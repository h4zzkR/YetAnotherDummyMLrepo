{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "neurama.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "2YP6Lo_Q6PpU"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "a77d8d9bacee4cfdae42ca5104eeffcc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_28103de955144005a71e0117953ace84",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_a2e6411690a74b8a939fdb71210d81c3",
              "IPY_MODEL_649dcfda97e549deb8824846026ad493"
            ]
          }
        },
        "28103de955144005a71e0117953ace84": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a2e6411690a74b8a939fdb71210d81c3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_49eafda4de36490b9dfe019b1f0b18f2",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1000,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1000,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_19b5f091465d4e5e8f34fe3d06c2aabf"
          }
        },
        "649dcfda97e549deb8824846026ad493": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_8cc537b9882043ffaa1d306b86a74457",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 1000/1000 [12:15&lt;00:00,  1.36it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_fd866a370e604b5a9113be4d4062bddd"
          }
        },
        "49eafda4de36490b9dfe019b1f0b18f2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "19b5f091465d4e5e8f34fe3d06c2aabf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "8cc537b9882043ffaa1d306b86a74457": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "fd866a370e604b5a9113be4d4062bddd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "4608c7fc654b4edd98dbc4224c21c2d6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_dd84a1488fcc49dca1b2d37595baf004",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_c7cb6a82fff34d0d833c41de6ba8db06",
              "IPY_MODEL_bc118606d5744e32969abae50421786f"
            ]
          }
        },
        "dd84a1488fcc49dca1b2d37595baf004": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c7cb6a82fff34d0d833c41de6ba8db06": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_f1f2290e8ca54fbe80535632f159f4d2",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 24000,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 24000,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_93dc77d2f62f4ce59052765f64b4822a"
          }
        },
        "bc118606d5744e32969abae50421786f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_440413bbd8cd4c11a5a1bc48a99b2c0d",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 24000/24000 [01:35&lt;00:00, 250.63it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_862ff64f7bc04650b22b13919f3f8e40"
          }
        },
        "f1f2290e8ca54fbe80535632f159f4d2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "93dc77d2f62f4ce59052765f64b4822a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "440413bbd8cd4c11a5a1bc48a99b2c0d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "862ff64f7bc04650b22b13919f3f8e40": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "fGJlqWYep0ic"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import requests\n",
        "import json\n",
        "from tqdm import tqdm_notebook as tqdm\n",
        "import time\n",
        "import re"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bcPoDNg30_s0"
      },
      "source": [
        "**Neural news headlines**\n",
        "\n",
        "For all questions: \n",
        "@h4zzkR (telegram)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pyZw5-1H-ttA"
      },
      "source": [
        "With data from russian media (Meduza) and pseudo-russian media (Panorama) and with help of ruGPT3 model we will get crazy headlines generator"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "utEpGibz07sb"
      },
      "source": [
        "# Let's get some data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZbXOHv7f1Nna"
      },
      "source": [
        "This is real data from real media"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5jh2DB5op5i-"
      },
      "source": [
        "class MeduzaParser:\n",
        "    def __init__(self):\n",
        "        self.stream = 'https://meduza.io/api/v3/search?chrono=news&locale=ru&page={page}&per_page=24'\n",
        "        self.headers = {'User-Agent' : \"Mozilla/5.0 (X11; Linux x86_64; rv:88.0) Gecko/20100101 Firefox/88.0\" }\n",
        "        self.scrapped_titles = []\n",
        "        self.processed = []\n",
        "\n",
        "    def get_page_data(self, page):\n",
        "        response = requests.get(self.stream.format(page = page), headers=self.headers).json()\n",
        "        for url, data in response['documents'].items():\n",
        "            try:\n",
        "                self.scrapped_titles.append(data['title'])\n",
        "            except KeyError:\n",
        "                continue\n",
        "\n",
        "    def parse(self, parse_range : tuple = (0, 2)):\n",
        "        for i in tqdm(range(parse_range[0], parse_range[1])):\n",
        "            self.get_page_data(i)\n",
        "        print(\"[LOG] got all data\")\n",
        "\n",
        "    def preprocess(self):\n",
        "        for title in tqdm(self.scrapped_titles):\n",
        "            title = title.replace('\\xa0', ' ')\n",
        "            title = re.sub(r'[^-\\а-яА-Яa-zA-Z0-9,.: ]', '', title)\n",
        "            self.processed.append(title)\n",
        "\n",
        "    def to_csv(self):\n",
        "        df = pd.DataFrame(self.processed)\n",
        "        df.columns = ['title']\n",
        "        df.to_csv(\"meduza_snippet.csv\")\n",
        "        return df\n",
        "\n",
        "    def run(self, range_range : tuple = (0, 2)):\n",
        "        self.parse(range_range)\n",
        "        self.preprocess()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 609,
          "referenced_widgets": [
            "a77d8d9bacee4cfdae42ca5104eeffcc",
            "28103de955144005a71e0117953ace84",
            "a2e6411690a74b8a939fdb71210d81c3",
            "649dcfda97e549deb8824846026ad493",
            "49eafda4de36490b9dfe019b1f0b18f2",
            "19b5f091465d4e5e8f34fe3d06c2aabf",
            "8cc537b9882043ffaa1d306b86a74457",
            "fd866a370e604b5a9113be4d4062bddd",
            "4608c7fc654b4edd98dbc4224c21c2d6",
            "dd84a1488fcc49dca1b2d37595baf004",
            "c7cb6a82fff34d0d833c41de6ba8db06",
            "bc118606d5744e32969abae50421786f",
            "f1f2290e8ca54fbe80535632f159f4d2",
            "93dc77d2f62f4ce59052765f64b4822a",
            "440413bbd8cd4c11a5a1bc48a99b2c0d",
            "862ff64f7bc04650b22b13919f3f8e40"
          ]
        },
        "id": "pHRHHnZdp5l5",
        "outputId": "3bcc02d1-764c-4445-d181-1b075919d8b9"
      },
      "source": [
        "mp = MeduzaParser()\n",
        "mp.run((1000,2000))\n",
        "mp.to_csv()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:17: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
            "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a77d8d9bacee4cfdae42ca5104eeffcc",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=1000.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "[LOG] got all data\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:22: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
            "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4608c7fc654b4edd98dbc4224c21c2d6",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=24000.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>title</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Сколько преступлений выявили в силовых структу...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Почему Любовь Соболь, Дмитрия Гудкова и других...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>В США задержали россиянина за нелегальную пере...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Коммерсант: в 2019 году сорвалась четверть гос...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>В Бразилии найден мертвым наркоторговец, пытав...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23995</th>\n",
              "      <td>Сможете стать президентом России</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23996</th>\n",
              "      <td>На Артдокфесте сорвали показ фильма о войне на...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23997</th>\n",
              "      <td>Александр Сокуров и русская Смерть</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23998</th>\n",
              "      <td>Хочу организовать городской фестиваль своими с...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23999</th>\n",
              "      <td>Что такое медленная мода Это мне подходит</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>24000 rows × 1 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                   title\n",
              "0      Сколько преступлений выявили в силовых структу...\n",
              "1      Почему Любовь Соболь, Дмитрия Гудкова и других...\n",
              "2      В США задержали россиянина за нелегальную пере...\n",
              "3      Коммерсант: в 2019 году сорвалась четверть гос...\n",
              "4      В Бразилии найден мертвым наркоторговец, пытав...\n",
              "...                                                  ...\n",
              "23995                   Сможете стать президентом России\n",
              "23996  На Артдокфесте сорвали показ фильма о войне на...\n",
              "23997                 Александр Сокуров и русская Смерть\n",
              "23998  Хочу организовать городской фестиваль своими с...\n",
              "23999          Что такое медленная мода Это мне подходит\n",
              "\n",
              "[24000 rows x 1 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KX8H65Vy1g_8"
      },
      "source": [
        "And this is not real data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": "OK"
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 100
        },
        "id": "LzvnPw9Q3HwM",
        "outputId": "299355f6-a885-4461-863f-aade116b5e3b"
      },
      "source": [
        "from google.colab import files\n",
        "\n",
        "uploaded = files.upload()\n",
        "\n",
        "for fn in uploaded.keys():\n",
        "  print('User uploaded file \"{name}\" with length {length} bytes'.format(\n",
        "      name=fn, length=len(uploaded[fn])))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-30721c3e-a57d-42d3-8bd4-48d9612e3eeb\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-30721c3e-a57d-42d3-8bd4-48d9612e3eeb\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving panorama_data.json to panorama_data.json\n",
            "User uploaded file \"panorama_data.json\" with length 4023793 bytes\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y6okE7oH3QzC"
      },
      "source": [
        "class PanoramaOfflineParser:\n",
        "    def __init__(self, path = 'panorama_data.json'):\n",
        "        with open(path) as json_file:\n",
        "            self.json_file = json.load(json_file)\n",
        "        self.processed = []\n",
        "\n",
        "    def run(self):\n",
        "        for msg in self.json_file['messages']:\n",
        "            try:\n",
        "                hl = msg['text'][0]\n",
        "            except Exception:\n",
        "                if isinstance(msg['text'], str):\n",
        "                    hl = msg['text']\n",
        "            if isinstance(hl, str):\n",
        "                hl = hl[:hl.find('\\n')]\n",
        "                if (len(hl) != 0):\n",
        "                    hl = re.sub(r'[^-\\а-яА-Яa-zA-Z0-9,.: ]', '', hl)\n",
        "                    self.processed.append(hl)\n",
        "      \n",
        "    def to_csv(self):\n",
        "        df = pd.DataFrame(self.processed)\n",
        "        df.columns = ['title']\n",
        "        df.to_csv(\"panorama_snippet.csv\")\n",
        "        return df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MpVaEM-lZfvE",
        "outputId": "db6622f0-ecf5-4fc1-9fbf-f1dbf7ddda2e"
      },
      "source": [
        "# from google.colab import files\n",
        "\n",
        "# uploaded = files.upload()\n",
        "\n",
        "# for fn in uploaded.keys():\n",
        "#   print('User uploaded file \"{name}\" with length {length} bytes'.format(\n",
        "#       name=fn, length=len(uploaded[fn])))\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/gdrive')\n",
        "%ls /gdrive\n",
        "\n",
        "meduza_path = '/gdrive/MyDrive/neurama/meduza_snippet(1).csv'\n",
        "panorama_path = '/gdrive/MyDrive/neurama/panorama_data.json'"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /gdrive; to attempt to forcibly remount, call drive.mount(\"/gdrive\", force_remount=True).\n",
            "\u001b[0m\u001b[01;34mMyDrive\u001b[0m/  \u001b[01;34mShareddrives\u001b[0m/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "E5Me7rxt4STU",
        "outputId": "0f575470-ed3b-4638-fdb4-ea520aaafd1a"
      },
      "source": [
        "pp = PanoramaOfflineParser(panorama_path)\n",
        "pp.run()\n",
        "pp.to_csv()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>title</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Конгресс США по ошибке проголосовал за включен...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Инициативные россияне создали движение А мы и ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>UBER создаст в Румынии первую в мире сеть гуже...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Престарелый чернокожий экс-работник General Mo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Минобороны построило в Анапе детскую площадку ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6856</th>\n",
              "      <td>Навальный станет лидером России в Civilization 6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6857</th>\n",
              "      <td>Накануне Дня Победы из алтаря храма Вооружнных...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6858</th>\n",
              "      <td>В Белоруссии объявили о начале всеобщей коллек...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6859</th>\n",
              "      <td>Российские торрент-трекеры обязали раздавать п...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6860</th>\n",
              "      <td>Минобороны предложило на период военных сборов...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>6861 rows × 1 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                  title\n",
              "0     Конгресс США по ошибке проголосовал за включен...\n",
              "1     Инициативные россияне создали движение А мы и ...\n",
              "2     UBER создаст в Румынии первую в мире сеть гуже...\n",
              "3     Престарелый чернокожий экс-работник General Mo...\n",
              "4     Минобороны построило в Анапе детскую площадку ...\n",
              "...                                                 ...\n",
              "6856   Навальный станет лидером России в Civilization 6\n",
              "6857  Накануне Дня Победы из алтаря храма Вооружнных...\n",
              "6858  В Белоруссии объявили о начале всеобщей коллек...\n",
              "6859  Российские торрент-трекеры обязали раздавать п...\n",
              "6860  Минобороны предложило на период военных сборов...\n",
              "\n",
              "[6861 rows x 1 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RcDIb6uo7Moo"
      },
      "source": [
        "ms = pd.read_csv(meduza_path)\n",
        "ps = pd.read_csv('panorama_snippet.csv')\n",
        "\n",
        "ms.reset_index(drop=True, inplace=True)\n",
        "ps.reset_index(drop=True, inplace=True)\n",
        "\n",
        "df = pd.concat([ms, ps])\n",
        "df = df.loc[:, ~df.columns.str.contains('^Unnamed')]\n",
        "\n",
        "from sklearn.utils import shuffle\n",
        "df = shuffle(df).reset_index(drop=True)\n",
        "\n",
        "df.to_csv('snippet.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "FcrX2a539Uui",
        "outputId": "ec050637-4b88-4636-80d8-e3b265206dc6"
      },
      "source": [
        "df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>title</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Саудовские генетики вырастили верблюда, приспо...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Телеканал Дождь в новогоднюю ночь показал выст...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Путин подписал законы о повышении НДС и о новы...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Мальчик русский: фильм ученика Сокурова о Перв...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Полковник Владимир Квачков вышел на свободу</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30856</th>\n",
              "      <td>Правда, что таксисты работают сутками и зараба...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30857</th>\n",
              "      <td>Создателя 10-часового видео с белым шумом обви...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30858</th>\n",
              "      <td>Участники акции против строительства храма в ц...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30859</th>\n",
              "      <td>Есть много белых пятен. Как госорганы объясняю...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30860</th>\n",
              "      <td>Вдове филиппинского диктатора Фердинанда Марко...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>30861 rows × 1 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                   title\n",
              "0      Саудовские генетики вырастили верблюда, приспо...\n",
              "1      Телеканал Дождь в новогоднюю ночь показал выст...\n",
              "2      Путин подписал законы о повышении НДС и о новы...\n",
              "3      Мальчик русский: фильм ученика Сокурова о Перв...\n",
              "4            Полковник Владимир Квачков вышел на свободу\n",
              "...                                                  ...\n",
              "30856  Правда, что таксисты работают сутками и зараба...\n",
              "30857  Создателя 10-часового видео с белым шумом обви...\n",
              "30858  Участники акции против строительства храма в ц...\n",
              "30859  Есть много белых пятен. Как госорганы объясняю...\n",
              "30860  Вдове филиппинского диктатора Фердинанда Марко...\n",
              "\n",
              "[30861 rows x 1 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2YP6Lo_Q6PpU"
      },
      "source": [
        "# Char-based generation with RNNs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cu0RVk8B6VSA"
      },
      "source": [
        "df = pd.read_csv('snippet.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NQMgxSX69egr",
        "outputId": "c5db48ea-d1f2-415e-fbc8-44a3a93b31cc"
      },
      "source": [
        "maxlen = df['title'].str.len().max()\n",
        "print(f'Title max length is {maxlen}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Title max length is 249.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sObmSi_O91F9",
        "outputId": "21dbcb74-baf0-459f-9c94-1b93aa102b23"
      },
      "source": [
        "drop_factor = 70\n",
        "\n",
        "old_size = df.shape[0]\n",
        "df = df[df['title'].str.len() < drop_factor]\n",
        "df['title'] = df['title'].str.lower()\n",
        "new_size = df.shape[0]\n",
        "\n",
        "print(f\"Size before cutting: {old_size}, size after cut: {new_size}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Size before cutting: 3318, size after cut: 3318\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PYfyTsTL8FUo",
        "outputId": "14e844b1-cd20-4e6d-bb2a-4977958754e0"
      },
      "source": [
        "text = df[\"title\"].str.cat(sep='\\n')\n",
        "text_size = len(text)\n",
        "print('Text Size: %d' % text_size)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Text Size: 188593\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "-87MbLIl77KS",
        "outputId": "d2eaf77d-6d3d-461b-c281-3aaa52f89abe"
      },
      "source": [
        "from pickle import dump\n",
        "\n",
        "chars = list(set(text))\n",
        "char2int = {c : i for i, c in enumerate(chars)}\n",
        "int2char = {i : c for i, c in enumerate(chars)}\n",
        "\n",
        "\n",
        "dump(char2int, open('mapping.pkl', 'wb'))\n",
        "\n",
        "vocab_size = len(char2int)\n",
        "print(f\"vocab size: {vocab_size}\")\n",
        "\n",
        "encoded_text = [char2int[char] for char in text]\n",
        "encode_size = len(encoded_text)\n",
        "\n",
        "print(f\"encode size: {encode_size}\")\n",
        "\n",
        "eos = char2int['\\n']\n",
        "int2char[eos]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "vocab size: 74\n",
            "encode size: 188593\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AoEVosk4--Hh"
      },
      "source": [
        "seqlen = 10\n",
        "batchsize = 512\n",
        "batchnum = int((encode_size - seqlen) / batchsize)\n",
        "\n",
        "from keras.utils import to_categorical\n",
        "\n",
        "def myGenerator():\n",
        "    while 1:\n",
        "        for i in range(batchnum): \n",
        "            X_batch = []\n",
        "            y_batch = []\n",
        "            for j in range(batchsize):\n",
        "                X_batch.append(encoded_text[i*batchsize+j:i*batchsize+j+seqlen])\n",
        "                y_batch.append(encoded_text[i*batchsize+j+seqlen:i*batchsize+j+seqlen+1])\n",
        "                \n",
        "            X_batch = np.array([to_categorical(x, num_classes=vocab_size) for x in X_batch])\n",
        "            y_batch = np.array(to_categorical(y_batch, num_classes=vocab_size))\n",
        "\n",
        "            yield (X_batch, y_batch)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SlBMcBGP_JGj",
        "outputId": "fc3ba0f4-4f18-490f-d26e-5ef5136e2ef5"
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Input, Dense, LSTM, SimpleRNN\n",
        "from keras.models import Model\n",
        "\n",
        "model = Sequential()\n",
        "model.add(LSTM(512, return_sequences=True, input_shape=(seqlen, vocab_size)))\n",
        "model.add(LSTM(256, return_sequences=True))\n",
        "model.add(LSTM(vocab_size))\n",
        "model.add(Dense(vocab_size, activation='softmax'))\n",
        "print(model.summary())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm_3 (LSTM)                (None, 10, 512)           1202176   \n",
            "_________________________________________________________________\n",
            "lstm_4 (LSTM)                (None, 10, 256)           787456    \n",
            "_________________________________________________________________\n",
            "lstm_5 (LSTM)                (None, 74)                97976     \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 74)                5550      \n",
            "=================================================================\n",
            "Total params: 2,093,158\n",
            "Trainable params: 2,093,158\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j8j95Ydf_L3G",
        "outputId": "5a086b80-3085-4a82-bef8-be19db488cc9"
      },
      "source": [
        "# my_generator = myGenerator()\n",
        "# model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "history = model.fit_generator(my_generator, steps_per_epoch = batchnum, epochs = 50, verbose=1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "  3/368 [..............................] - ETA: 13s - loss: 0.6982 - accuracy: 0.7904"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "368/368 [==============================] - 10s 26ms/step - loss: 0.6626 - accuracy: 0.8080\n",
            "Epoch 2/50\n",
            "368/368 [==============================] - 9s 26ms/step - loss: 0.6452 - accuracy: 0.8119\n",
            "Epoch 3/50\n",
            "368/368 [==============================] - 9s 26ms/step - loss: 0.6282 - accuracy: 0.8178\n",
            "Epoch 4/50\n",
            "368/368 [==============================] - 9s 26ms/step - loss: 0.6027 - accuracy: 0.8261\n",
            "Epoch 5/50\n",
            "368/368 [==============================] - 10s 26ms/step - loss: 0.5728 - accuracy: 0.8367\n",
            "Epoch 6/50\n",
            "368/368 [==============================] - 10s 26ms/step - loss: 0.5448 - accuracy: 0.8466\n",
            "Epoch 7/50\n",
            "368/368 [==============================] - 10s 26ms/step - loss: 0.5179 - accuracy: 0.8556\n",
            "Epoch 8/50\n",
            "368/368 [==============================] - 10s 26ms/step - loss: 0.4974 - accuracy: 0.8621\n",
            "Epoch 9/50\n",
            "368/368 [==============================] - 10s 26ms/step - loss: 0.4803 - accuracy: 0.8675\n",
            "Epoch 10/50\n",
            "368/368 [==============================] - 10s 26ms/step - loss: 0.4718 - accuracy: 0.8690\n",
            "Epoch 11/50\n",
            "368/368 [==============================] - 10s 26ms/step - loss: 0.4619 - accuracy: 0.8707\n",
            "Epoch 12/50\n",
            "368/368 [==============================] - 10s 26ms/step - loss: 0.4522 - accuracy: 0.8734\n",
            "Epoch 13/50\n",
            "368/368 [==============================] - 10s 26ms/step - loss: 0.4442 - accuracy: 0.8743\n",
            "Epoch 14/50\n",
            "368/368 [==============================] - 10s 26ms/step - loss: 0.4336 - accuracy: 0.8768\n",
            "Epoch 15/50\n",
            "368/368 [==============================] - 10s 26ms/step - loss: 0.4207 - accuracy: 0.8801\n",
            "Epoch 16/50\n",
            "368/368 [==============================] - 10s 26ms/step - loss: 0.4105 - accuracy: 0.8828\n",
            "Epoch 17/50\n",
            "368/368 [==============================] - 10s 26ms/step - loss: 0.3985 - accuracy: 0.8876\n",
            "Epoch 18/50\n",
            "368/368 [==============================] - 10s 26ms/step - loss: 0.3857 - accuracy: 0.8915\n",
            "Epoch 19/50\n",
            "368/368 [==============================] - 10s 26ms/step - loss: 0.3805 - accuracy: 0.8912\n",
            "Epoch 20/50\n",
            "368/368 [==============================] - 10s 26ms/step - loss: 0.3750 - accuracy: 0.8930\n",
            "Epoch 21/50\n",
            "368/368 [==============================] - 10s 26ms/step - loss: 0.3631 - accuracy: 0.8967\n",
            "Epoch 22/50\n",
            "368/368 [==============================] - 10s 26ms/step - loss: 0.3530 - accuracy: 0.8995\n",
            "Epoch 23/50\n",
            "368/368 [==============================] - 10s 26ms/step - loss: 0.3467 - accuracy: 0.9015\n",
            "Epoch 24/50\n",
            "368/368 [==============================] - 10s 26ms/step - loss: 0.3388 - accuracy: 0.9033\n",
            "Epoch 25/50\n",
            "368/368 [==============================] - 10s 26ms/step - loss: 0.3294 - accuracy: 0.9062\n",
            "Epoch 26/50\n",
            "368/368 [==============================] - 10s 27ms/step - loss: 0.3222 - accuracy: 0.9083\n",
            "Epoch 27/50\n",
            "368/368 [==============================] - 10s 26ms/step - loss: 0.3145 - accuracy: 0.9100\n",
            "Epoch 28/50\n",
            "368/368 [==============================] - 10s 26ms/step - loss: 0.3079 - accuracy: 0.9126\n",
            "Epoch 29/50\n",
            "368/368 [==============================] - 10s 26ms/step - loss: 0.3004 - accuracy: 0.9141\n",
            "Epoch 30/50\n",
            "368/368 [==============================] - 10s 26ms/step - loss: 0.2929 - accuracy: 0.9169\n",
            "Epoch 31/50\n",
            "368/368 [==============================] - 10s 26ms/step - loss: 0.2892 - accuracy: 0.9178\n",
            "Epoch 32/50\n",
            "368/368 [==============================] - 10s 26ms/step - loss: 0.2833 - accuracy: 0.9181\n",
            "Epoch 33/50\n",
            "368/368 [==============================] - 10s 26ms/step - loss: 0.2781 - accuracy: 0.9200\n",
            "Epoch 34/50\n",
            "368/368 [==============================] - 10s 27ms/step - loss: 0.2765 - accuracy: 0.9196\n",
            "Epoch 35/50\n",
            "368/368 [==============================] - 10s 26ms/step - loss: 0.2710 - accuracy: 0.9212\n",
            "Epoch 36/50\n",
            "368/368 [==============================] - 10s 26ms/step - loss: 0.2637 - accuracy: 0.9236\n",
            "Epoch 37/50\n",
            "368/368 [==============================] - 10s 26ms/step - loss: 0.2575 - accuracy: 0.9258\n",
            "Epoch 38/50\n",
            "368/368 [==============================] - 10s 26ms/step - loss: 0.2527 - accuracy: 0.9273\n",
            "Epoch 39/50\n",
            "368/368 [==============================] - 10s 26ms/step - loss: 0.2456 - accuracy: 0.9292\n",
            "Epoch 40/50\n",
            "368/368 [==============================] - 10s 26ms/step - loss: 0.2391 - accuracy: 0.9310\n",
            "Epoch 41/50\n",
            "368/368 [==============================] - 10s 26ms/step - loss: 0.2319 - accuracy: 0.9334\n",
            "Epoch 42/50\n",
            "368/368 [==============================] - 10s 26ms/step - loss: 0.2234 - accuracy: 0.9358\n",
            "Epoch 43/50\n",
            "368/368 [==============================] - 10s 26ms/step - loss: 0.2133 - accuracy: 0.9401\n",
            "Epoch 44/50\n",
            "368/368 [==============================] - 10s 26ms/step - loss: 0.2043 - accuracy: 0.9421\n",
            "Epoch 45/50\n",
            "368/368 [==============================] - 10s 26ms/step - loss: 0.1941 - accuracy: 0.9454\n",
            "Epoch 46/50\n",
            "368/368 [==============================] - 10s 26ms/step - loss: 0.1882 - accuracy: 0.9479\n",
            "Epoch 47/50\n",
            "368/368 [==============================] - 10s 26ms/step - loss: 0.1831 - accuracy: 0.9500\n",
            "Epoch 48/50\n",
            "368/368 [==============================] - 10s 26ms/step - loss: 0.1760 - accuracy: 0.9514\n",
            "Epoch 49/50\n",
            "368/368 [==============================] - 10s 26ms/step - loss: 0.1746 - accuracy: 0.9515\n",
            "Epoch 50/50\n",
            "368/368 [==============================] - 10s 26ms/step - loss: 0.1724 - accuracy: 0.9520\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R31s0Hmu_57O",
        "outputId": "907460b4-3e9b-4e67-c6de-2d180440eda4"
      },
      "source": [
        "from pickle import load\n",
        "from keras.models import load_model\n",
        "from keras.utils import to_categorical\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "import random\n",
        " \n",
        "def generate_seq(model, mapping, seq_length, seed_text, n_chars):\n",
        "    in_text = seed_text\n",
        "    for _ in range(n_chars):\n",
        "        encoded = [mapping[char2] for char2 in in_text]\n",
        "        encoded = pad_sequences([encoded], maxlen=seq_length, truncating='pre')\n",
        "        encoded = to_categorical(encoded, num_classes=len(mapping))\n",
        "        probs = model.predict_proba(encoded)\n",
        "        yhat = random.choices(range(0,vocab_size), weights=probs[0], k=1)[0]\n",
        "        out_char = ''\n",
        "        for char, index in mapping.items():\n",
        "            if index == yhat:\n",
        "                out_char = char\n",
        "                break\n",
        "        in_text += out_char\n",
        "        if char ==\"\\n\":\n",
        "            break\n",
        "    return in_text\n",
        "\n",
        "print(generate_seq(model, char2int, seqlen, 'навальный ', 50))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:425: UserWarning: `model.predict_proba()` is deprecated and will be removed after 2021-01-01. Please use `model.predict()` instead.\n",
            "  warnings.warn('`model.predict_proba()` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "навальный выдал кадры из чтобзк-в сорсал милай \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kNlixEwgxcEz"
      },
      "source": [
        "# ruGPT2(3) transformer\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FiaTHN7jrkJ4"
      },
      "source": [
        "Теперь играем по-крупному"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wNCvqG-Oxhm2",
        "outputId": "21a8f558-35e5-4a16-efa4-31e49562b438"
      },
      "source": [
        "!pip install torch==1.4.0\n",
        "!pip3 install transformers==3.5.0"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torch==1.4.0 in /usr/local/lib/python3.7/dist-packages (1.4.0)\n",
            "Requirement already satisfied: transformers==3.5.0 in /usr/local/lib/python3.7/dist-packages (3.5.0)\n",
            "Requirement already satisfied: tokenizers==0.9.3 in /usr/local/lib/python3.7/dist-packages (from transformers==3.5.0) (0.9.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers==3.5.0) (2.23.0)\n",
            "Requirement already satisfied: sentencepiece==0.1.91 in /usr/local/lib/python3.7/dist-packages (from transformers==3.5.0) (0.1.91)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from transformers==3.5.0) (1.19.5)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers==3.5.0) (2019.12.20)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers==3.5.0) (3.0.12)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers==3.5.0) (4.41.1)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers==3.5.0) (0.0.45)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers==3.5.0) (20.9)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.7/dist-packages (from transformers==3.5.0) (3.12.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3.5.0) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3.5.0) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3.5.0) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3.5.0) (2020.12.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==3.5.0) (1.15.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==3.5.0) (1.0.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==3.5.0) (7.1.2)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers==3.5.0) (2.4.7)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from protobuf->transformers==3.5.0) (56.1.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r4Nukkg61Rxm",
        "outputId": "6ae74529-239e-4989-a3f7-8ced5714d207"
      },
      "source": [
        "!git clone  https://github.com/sberbank-ai/ru-gpts"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'ru-gpts' already exists and is not an empty directory.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NSazVfN21Tcl"
      },
      "source": [
        "!mkdir models/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "go-GXLVb_Tpt"
      },
      "source": [
        "## Data preparings"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wR5tJpY5_cGz"
      },
      "source": [
        "df['title'] = df['title'].apply(lambda row: '<s>' + str(row) + '</s>')\n",
        "text = ''\n",
        "for (_, row) in df.iterrows():\n",
        "  text += row.title"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xa1TFsKyEOVh"
      },
      "source": [
        "text[0:1000]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QbD-8z0LEkIg"
      },
      "source": [
        "text_file = open(\"train.txt\", \"w\")\n",
        "text_file.write(text)\n",
        "text_file.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MmS38IdD_YpJ"
      },
      "source": [
        "## Model training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BNAEOp7QEusX"
      },
      "source": [
        "    # --do_eval \\\n",
        "    # --eval_data_file=valid.txt \\"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xvlYpxpj1lb9",
        "outputId": "d77aa86e-c5e9-4f27-8224-7db51e82bff4"
      },
      "source": [
        "!export PYTHONPATH=${PYTHONPATH}:/ru-gpts/\n",
        "!CUDA_VISIBLE_DEVICES=0 python ru-gpts/pretrain_transformers.py \\\n",
        "    --output_dir=models/ \\\n",
        "    --model_type=gpt2 \\\n",
        "    --model_name_or_path=sberbank-ai/rugpt3small_based_on_gpt2 \\\n",
        "    --do_train \\\n",
        "    --train_data_file=train.txt \\\n",
        "    --per_gpu_train_batch_size 1 \\\n",
        "    --gradient_accumulation_steps 1 \\\n",
        "    --num_train_epochs 2 \\\n",
        "    --block_size 2048 \\\n",
        "    --overwrite_output_dir"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-05-14 09:47:05.889663: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
            "05/14/2021 09:47:08 - WARNING - __main__ -   Process rank: -1, device: cuda, n_gpu: 1, distributed training: False, 16-bits training: False\n",
            "05/14/2021 09:47:08 - INFO - filelock -   Lock 140146140535504 acquired on /root/.cache/torch/transformers/06f48b6b3173390d047e15d691fda67ae4ea7733a5eea4b6e0115f5099c4e700.b5cdfa39c63384f94159c36bc9042660c747cea5cf520b43d543bd2c68b3164d.lock\n",
            "Downloading: 100% 608/608 [00:00<00:00, 522kB/s]\n",
            "05/14/2021 09:47:08 - INFO - filelock -   Lock 140146140535504 released on /root/.cache/torch/transformers/06f48b6b3173390d047e15d691fda67ae4ea7733a5eea4b6e0115f5099c4e700.b5cdfa39c63384f94159c36bc9042660c747cea5cf520b43d543bd2c68b3164d.lock\n",
            "05/14/2021 09:47:09 - INFO - filelock -   Lock 140146140500560 acquired on /root/.cache/torch/transformers/1b36eeb1fd7b3a6ec11bf46bde2c38e7e68f71ec774694b9e886c86001aab35d.c483bc3440d25937fdac74506b73b76ee6e67f778a804756214363fc2a1a66ef.lock\n",
            "Downloading: 100% 1.71M/1.71M [00:00<00:00, 4.33MB/s]\n",
            "05/14/2021 09:47:09 - INFO - filelock -   Lock 140146140500560 released on /root/.cache/torch/transformers/1b36eeb1fd7b3a6ec11bf46bde2c38e7e68f71ec774694b9e886c86001aab35d.c483bc3440d25937fdac74506b73b76ee6e67f778a804756214363fc2a1a66ef.lock\n",
            "05/14/2021 09:47:09 - INFO - filelock -   Lock 140146140500304 acquired on /root/.cache/torch/transformers/479aa59074c4dcd4c36106252da033d03bc92e3010947ce1d3714de224c2af1f.7362c0dbb32f750eeea5a5b93bbd0c6876eac41453369265d5a49df1c9142b6f.lock\n",
            "Downloading: 100% 1.27M/1.27M [00:00<00:00, 3.15MB/s]\n",
            "05/14/2021 09:47:10 - INFO - filelock -   Lock 140146140500304 released on /root/.cache/torch/transformers/479aa59074c4dcd4c36106252da033d03bc92e3010947ce1d3714de224c2af1f.7362c0dbb32f750eeea5a5b93bbd0c6876eac41453369265d5a49df1c9142b6f.lock\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:1423: FutureWarning: The `max_len` attribute has been deprecated and will be removed in a future version, use `model_max_length` instead.\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/modeling_auto.py:837: FutureWarning: The class `AutoModelWithLMHead` is deprecated and will be removed in a future version. Please use `AutoModelForCausalLM` for causal language models, `AutoModelForMaskedLM` for masked language models and `AutoModelForSeq2SeqLM` for encoder-decoder models.\n",
            "  FutureWarning,\n",
            "05/14/2021 09:47:11 - INFO - filelock -   Lock 140145844294992 acquired on /root/.cache/torch/transformers/df2b64a4c86a349ba84354d85b7117b106f2b87085c9bb54cde70d3751907c45.4e3da19dd8adaa6d6a9804bfd45d2dcf17ba544de445847443ef1816bfa3d693.lock\n",
            "Downloading: 100% 551M/551M [00:09<00:00, 58.4MB/s]\n",
            "05/14/2021 09:47:21 - INFO - filelock -   Lock 140145844294992 released on /root/.cache/torch/transformers/df2b64a4c86a349ba84354d85b7117b106f2b87085c9bb54cde70d3751907c45.4e3da19dd8adaa6d6a9804bfd45d2dcf17ba544de445847443ef1816bfa3d693.lock\n",
            "05/14/2021 09:47:27 - INFO - __main__ -   Training/evaluation parameters Namespace(adam_epsilon=1e-08, block_size=2048, cache_dir=None, config_name=None, device=device(type='cuda'), do_eval=False, do_train=True, eval_all_checkpoints=False, eval_data_file=None, evaluate_during_training=False, fp16=False, fp16_opt_level='O1', gradient_accumulation_steps=1, learning_rate=5e-05, line_by_line=False, local_rank=-1, logging_steps=500, max_grad_norm=1.0, max_steps=-1, mlm=False, mlm_probability=0.15, model_name_or_path='sberbank-ai/rugpt3small_based_on_gpt2', model_type='gpt2', n_gpu=1, no_cuda=False, num_train_epochs=2.0, output_dir='models/', overwrite_cache=False, overwrite_output_dir=True, per_gpu_eval_batch_size=4, per_gpu_train_batch_size=1, save_steps=500, save_total_limit=None, seed=42, server_ip='', server_port='', should_continue=False, tokenizer_name=None, train_data_file='train.txt', warmup_steps=0, weight_decay=0.01)\n",
            "05/14/2021 09:47:27 - INFO - __main__ -   Creating features from dataset file at \n",
            "05/14/2021 09:47:37 - INFO - __main__ -   Saving features into cached file gpt2_cached_lm_2048_train.txt\n",
            "05/14/2021 09:47:38 - INFO - __main__ -   ***** Running training *****\n",
            "05/14/2021 09:47:38 - INFO - __main__ -     Num examples = 361\n",
            "05/14/2021 09:47:38 - INFO - __main__ -     Num Epochs = 2\n",
            "05/14/2021 09:47:38 - INFO - __main__ -     Instantaneous batch size per GPU = 1\n",
            "05/14/2021 09:47:38 - INFO - __main__ -     Total train batch size (w. parallel, distributed & accumulation) = 1\n",
            "05/14/2021 09:47:38 - INFO - __main__ -     Gradient Accumulation steps = 1\n",
            "05/14/2021 09:47:38 - INFO - __main__ -     Total optimization steps = 722\n",
            "Epoch:   0% 0/2 [00:00<?, ?it/s]\n",
            "Iteration:   0% 0/361 [00:00<?, ?it/s]\u001b[A\n",
            "Iteration:   0% 1/361 [00:00<05:43,  1.05it/s]\u001b[A\n",
            "Iteration:   1% 2/361 [00:01<05:34,  1.07it/s]\u001b[A\n",
            "Iteration:   1% 3/361 [00:02<05:27,  1.09it/s]\u001b[A\n",
            "Iteration:   1% 4/361 [00:03<05:23,  1.11it/s]\u001b[A\n",
            "Iteration:   1% 5/361 [00:04<05:19,  1.12it/s]\u001b[A\n",
            "Iteration:   2% 6/361 [00:05<05:17,  1.12it/s]\u001b[A\n",
            "Iteration:   2% 7/361 [00:06<05:15,  1.12it/s]\u001b[A\n",
            "Iteration:   2% 8/361 [00:07<05:14,  1.12it/s]\u001b[A\n",
            "Iteration:   2% 9/361 [00:08<05:12,  1.13it/s]\u001b[A\n",
            "Iteration:   3% 10/361 [00:08<05:10,  1.13it/s]\u001b[A\n",
            "Iteration:   3% 11/361 [00:09<05:09,  1.13it/s]\u001b[A\n",
            "Iteration:   3% 12/361 [00:10<05:09,  1.13it/s]\u001b[A\n",
            "Iteration:   4% 13/361 [00:11<05:09,  1.13it/s]\u001b[A\n",
            "Iteration:   4% 14/361 [00:12<05:08,  1.12it/s]\u001b[A\n",
            "Iteration:   4% 15/361 [00:13<05:08,  1.12it/s]\u001b[A\n",
            "Iteration:   4% 16/361 [00:14<05:07,  1.12it/s]\u001b[A\n",
            "Iteration:   5% 17/361 [00:15<05:07,  1.12it/s]\u001b[A\n",
            "Iteration:   5% 18/361 [00:16<05:06,  1.12it/s]\u001b[A\n",
            "Iteration:   5% 19/361 [00:16<05:05,  1.12it/s]\u001b[A\n",
            "Iteration:   6% 20/361 [00:17<05:04,  1.12it/s]\u001b[A\n",
            "Iteration:   6% 21/361 [00:18<05:04,  1.12it/s]\u001b[A\n",
            "Iteration:   6% 22/361 [00:19<05:03,  1.12it/s]\u001b[A\n",
            "Iteration:   6% 23/361 [00:20<05:02,  1.12it/s]\u001b[A\n",
            "Iteration:   7% 24/361 [00:21<05:01,  1.12it/s]\u001b[A\n",
            "Iteration:   7% 25/361 [00:22<05:00,  1.12it/s]\u001b[A\n",
            "Iteration:   7% 26/361 [00:23<04:59,  1.12it/s]\u001b[A\n",
            "Iteration:   7% 27/361 [00:24<04:58,  1.12it/s]\u001b[A\n",
            "Iteration:   8% 28/361 [00:24<04:57,  1.12it/s]\u001b[A\n",
            "Iteration:   8% 29/361 [00:25<04:57,  1.12it/s]\u001b[A\n",
            "Iteration:   8% 30/361 [00:26<04:57,  1.11it/s]\u001b[A\n",
            "Iteration:   9% 31/361 [00:27<04:56,  1.11it/s]\u001b[A\n",
            "Iteration:   9% 32/361 [00:28<04:55,  1.11it/s]\u001b[A\n",
            "Iteration:   9% 33/361 [00:29<04:55,  1.11it/s]\u001b[A\n",
            "Iteration:   9% 34/361 [00:30<04:54,  1.11it/s]\u001b[A\n",
            "Iteration:  10% 35/361 [00:31<04:54,  1.11it/s]\u001b[A\n",
            "Iteration:  10% 36/361 [00:32<04:53,  1.11it/s]\u001b[A\n",
            "Iteration:  10% 37/361 [00:33<04:52,  1.11it/s]\u001b[A\n",
            "Iteration:  11% 38/361 [00:33<04:52,  1.11it/s]\u001b[A\n",
            "Iteration:  11% 39/361 [00:34<04:52,  1.10it/s]\u001b[A\n",
            "Iteration:  11% 40/361 [00:35<04:51,  1.10it/s]\u001b[A\n",
            "Iteration:  11% 41/361 [00:36<04:51,  1.10it/s]\u001b[A\n",
            "Iteration:  12% 42/361 [00:37<04:50,  1.10it/s]\u001b[A\n",
            "Iteration:  12% 43/361 [00:38<04:48,  1.10it/s]\u001b[A\n",
            "Iteration:  12% 44/361 [00:39<04:47,  1.10it/s]\u001b[A\n",
            "Iteration:  12% 45/361 [00:40<04:46,  1.10it/s]\u001b[A\n",
            "Iteration:  13% 46/361 [00:41<04:46,  1.10it/s]\u001b[A\n",
            "Iteration:  13% 47/361 [00:42<04:45,  1.10it/s]\u001b[A\n",
            "Iteration:  13% 48/361 [00:43<04:45,  1.10it/s]\u001b[A\n",
            "Iteration:  14% 49/361 [00:44<04:45,  1.09it/s]\u001b[A\n",
            "Iteration:  14% 50/361 [00:44<04:44,  1.09it/s]\u001b[A\n",
            "Iteration:  14% 51/361 [00:45<04:43,  1.09it/s]\u001b[A\n",
            "Iteration:  14% 52/361 [00:46<04:42,  1.09it/s]\u001b[A\n",
            "Iteration:  15% 53/361 [00:47<04:42,  1.09it/s]\u001b[A\n",
            "Iteration:  15% 54/361 [00:48<04:41,  1.09it/s]\u001b[A\n",
            "Iteration:  15% 55/361 [00:49<04:40,  1.09it/s]\u001b[A\n",
            "Iteration:  16% 56/361 [00:50<04:40,  1.09it/s]\u001b[A\n",
            "Iteration:  16% 57/361 [00:51<04:39,  1.09it/s]\u001b[A\n",
            "Iteration:  16% 58/361 [00:52<04:38,  1.09it/s]\u001b[A\n",
            "Iteration:  16% 59/361 [00:53<04:38,  1.09it/s]\u001b[A\n",
            "Iteration:  17% 60/361 [00:54<04:38,  1.08it/s]\u001b[A\n",
            "Iteration:  17% 61/361 [00:55<04:37,  1.08it/s]\u001b[A\n",
            "Iteration:  17% 62/361 [00:55<04:36,  1.08it/s]\u001b[A\n",
            "Iteration:  17% 63/361 [00:56<04:35,  1.08it/s]\u001b[A\n",
            "Iteration:  18% 64/361 [00:57<04:34,  1.08it/s]\u001b[A\n",
            "Iteration:  18% 65/361 [00:58<04:34,  1.08it/s]\u001b[A\n",
            "Iteration:  18% 66/361 [00:59<04:33,  1.08it/s]\u001b[A\n",
            "Iteration:  19% 67/361 [01:00<04:31,  1.08it/s]\u001b[A\n",
            "Iteration:  19% 68/361 [01:01<04:31,  1.08it/s]\u001b[A\n",
            "Iteration:  19% 69/361 [01:02<04:31,  1.08it/s]\u001b[A\n",
            "Iteration:  19% 70/361 [01:03<04:30,  1.07it/s]\u001b[A\n",
            "Iteration:  20% 71/361 [01:04<04:30,  1.07it/s]\u001b[A\n",
            "Iteration:  20% 72/361 [01:05<04:29,  1.07it/s]\u001b[A\n",
            "Iteration:  20% 73/361 [01:06<04:28,  1.07it/s]\u001b[A\n",
            "Iteration:  20% 74/361 [01:07<04:28,  1.07it/s]\u001b[A\n",
            "Iteration:  21% 75/361 [01:08<04:27,  1.07it/s]\u001b[A\n",
            "Iteration:  21% 76/361 [01:09<04:26,  1.07it/s]\u001b[A\n",
            "Iteration:  21% 77/361 [01:09<04:25,  1.07it/s]\u001b[A\n",
            "Iteration:  22% 78/361 [01:10<04:24,  1.07it/s]\u001b[A\n",
            "Iteration:  22% 79/361 [01:11<04:23,  1.07it/s]\u001b[A\n",
            "Iteration:  22% 80/361 [01:12<04:23,  1.07it/s]\u001b[A\n",
            "Iteration:  22% 81/361 [01:13<04:22,  1.07it/s]\u001b[A\n",
            "Iteration:  23% 82/361 [01:14<04:22,  1.06it/s]\u001b[A\n",
            "Iteration:  23% 83/361 [01:15<04:21,  1.06it/s]\u001b[A\n",
            "Iteration:  23% 84/361 [01:16<04:21,  1.06it/s]\u001b[A\n",
            "Iteration:  24% 85/361 [01:17<04:20,  1.06it/s]\u001b[A\n",
            "Iteration:  24% 86/361 [01:18<04:19,  1.06it/s]\u001b[A\n",
            "Iteration:  24% 87/361 [01:19<04:19,  1.06it/s]\u001b[A\n",
            "Iteration:  24% 88/361 [01:20<04:18,  1.06it/s]\u001b[A\n",
            "Iteration:  25% 89/361 [01:21<04:17,  1.06it/s]\u001b[A\n",
            "Iteration:  25% 90/361 [01:22<04:17,  1.05it/s]\u001b[A\n",
            "Iteration:  25% 91/361 [01:23<04:16,  1.05it/s]\u001b[A\n",
            "Iteration:  25% 92/361 [01:24<04:15,  1.05it/s]\u001b[A\n",
            "Iteration:  26% 93/361 [01:25<04:14,  1.05it/s]\u001b[A\n",
            "Iteration:  26% 94/361 [01:26<04:13,  1.05it/s]\u001b[A\n",
            "Iteration:  26% 95/361 [01:27<04:13,  1.05it/s]\u001b[A\n",
            "Iteration:  27% 96/361 [01:27<04:12,  1.05it/s]\u001b[A\n",
            "Iteration:  27% 97/361 [01:28<04:11,  1.05it/s]\u001b[A\n",
            "Iteration:  27% 98/361 [01:29<04:10,  1.05it/s]\u001b[A\n",
            "Iteration:  27% 99/361 [01:30<04:10,  1.05it/s]\u001b[A\n",
            "Iteration:  28% 100/361 [01:31<04:09,  1.05it/s]\u001b[A\n",
            "Iteration:  28% 101/361 [01:32<04:08,  1.05it/s]\u001b[A\n",
            "Iteration:  28% 102/361 [01:33<04:07,  1.05it/s]\u001b[A\n",
            "Iteration:  29% 103/361 [01:34<04:05,  1.05it/s]\u001b[A\n",
            "Iteration:  29% 104/361 [01:35<04:04,  1.05it/s]\u001b[A\n",
            "Iteration:  29% 105/361 [01:36<04:04,  1.05it/s]\u001b[A\n",
            "Iteration:  29% 106/361 [01:37<04:03,  1.05it/s]\u001b[A\n",
            "Iteration:  30% 107/361 [01:38<04:02,  1.05it/s]\u001b[A\n",
            "Iteration:  30% 108/361 [01:39<04:01,  1.05it/s]\u001b[A\n",
            "Iteration:  30% 109/361 [01:40<04:00,  1.05it/s]\u001b[A\n",
            "Iteration:  30% 110/361 [01:41<03:59,  1.05it/s]\u001b[A\n",
            "Iteration:  31% 111/361 [01:42<03:58,  1.05it/s]\u001b[A\n",
            "Iteration:  31% 112/361 [01:43<03:57,  1.05it/s]\u001b[A\n",
            "Iteration:  31% 113/361 [01:44<03:57,  1.05it/s]\u001b[A\n",
            "Iteration:  32% 114/361 [01:45<03:56,  1.05it/s]\u001b[A\n",
            "Iteration:  32% 115/361 [01:46<03:56,  1.04it/s]\u001b[A\n",
            "Iteration:  32% 116/361 [01:47<03:55,  1.04it/s]\u001b[A\n",
            "Iteration:  32% 117/361 [01:48<03:54,  1.04it/s]\u001b[A\n",
            "Iteration:  33% 118/361 [01:48<03:53,  1.04it/s]\u001b[A\n",
            "Iteration:  33% 119/361 [01:49<03:52,  1.04it/s]\u001b[A\n",
            "Iteration:  33% 120/361 [01:50<03:52,  1.04it/s]\u001b[A\n",
            "Iteration:  34% 121/361 [01:51<03:51,  1.04it/s]\u001b[A\n",
            "Iteration:  34% 122/361 [01:52<03:51,  1.03it/s]\u001b[A\n",
            "Iteration:  34% 123/361 [01:53<03:49,  1.03it/s]\u001b[A\n",
            "Iteration:  34% 124/361 [01:54<03:49,  1.03it/s]\u001b[A\n",
            "Iteration:  35% 125/361 [01:55<03:48,  1.03it/s]\u001b[A\n",
            "Iteration:  35% 126/361 [01:56<03:47,  1.03it/s]\u001b[A\n",
            "Iteration:  35% 127/361 [01:57<03:46,  1.03it/s]\u001b[A\n",
            "Iteration:  35% 128/361 [01:58<03:45,  1.03it/s]\u001b[A\n",
            "Iteration:  36% 129/361 [01:59<03:45,  1.03it/s]\u001b[A\n",
            "Iteration:  36% 130/361 [02:00<03:44,  1.03it/s]\u001b[A\n",
            "Iteration:  36% 131/361 [02:01<03:43,  1.03it/s]\u001b[A\n",
            "Iteration:  37% 132/361 [02:02<03:43,  1.03it/s]\u001b[A\n",
            "Iteration:  37% 133/361 [02:03<03:42,  1.03it/s]\u001b[A\n",
            "Iteration:  37% 134/361 [02:04<03:41,  1.03it/s]\u001b[A\n",
            "Iteration:  37% 135/361 [02:05<03:40,  1.03it/s]\u001b[A\n",
            "Iteration:  38% 136/361 [02:06<03:39,  1.02it/s]\u001b[A\n",
            "Iteration:  38% 137/361 [02:07<03:38,  1.03it/s]\u001b[A\n",
            "Iteration:  38% 138/361 [02:08<03:37,  1.03it/s]\u001b[A\n",
            "Iteration:  39% 139/361 [02:09<03:36,  1.03it/s]\u001b[A\n",
            "Iteration:  39% 140/361 [02:10<03:35,  1.03it/s]\u001b[A\n",
            "Iteration:  39% 141/361 [02:11<03:34,  1.02it/s]\u001b[A\n",
            "Iteration:  39% 142/361 [02:12<03:34,  1.02it/s]\u001b[A\n",
            "Iteration:  40% 143/361 [02:13<03:33,  1.02it/s]\u001b[A\n",
            "Iteration:  40% 144/361 [02:14<03:32,  1.02it/s]\u001b[A\n",
            "Iteration:  40% 145/361 [02:15<03:32,  1.02it/s]\u001b[A\n",
            "Iteration:  40% 146/361 [02:16<03:30,  1.02it/s]\u001b[A\n",
            "Iteration:  41% 147/361 [02:17<03:30,  1.02it/s]\u001b[A\n",
            "Iteration:  41% 148/361 [02:18<03:29,  1.02it/s]\u001b[A\n",
            "Iteration:  41% 149/361 [02:19<03:28,  1.02it/s]\u001b[A\n",
            "Iteration:  42% 150/361 [02:20<03:28,  1.01it/s]\u001b[A\n",
            "Iteration:  42% 151/361 [02:21<03:26,  1.01it/s]\u001b[A\n",
            "Iteration:  42% 152/361 [02:22<03:26,  1.01it/s]\u001b[A\n",
            "Iteration:  42% 153/361 [02:23<03:25,  1.01it/s]\u001b[A\n",
            "Iteration:  43% 154/361 [02:24<03:25,  1.01it/s]\u001b[A\n",
            "Iteration:  43% 155/361 [02:25<03:24,  1.01it/s]\u001b[A\n",
            "Iteration:  43% 156/361 [02:26<03:23,  1.01it/s]\u001b[A\n",
            "Iteration:  43% 157/361 [02:27<03:22,  1.01it/s]\u001b[A\n",
            "Iteration:  44% 158/361 [02:28<03:20,  1.01it/s]\u001b[A\n",
            "Iteration:  44% 159/361 [02:29<03:18,  1.02it/s]\u001b[A\n",
            "Iteration:  44% 160/361 [02:30<03:17,  1.02it/s]\u001b[A\n",
            "Iteration:  45% 161/361 [02:31<03:16,  1.02it/s]\u001b[A\n",
            "Iteration:  45% 162/361 [02:32<03:15,  1.02it/s]\u001b[A\n",
            "Iteration:  45% 163/361 [02:33<03:15,  1.01it/s]\u001b[A\n",
            "Iteration:  45% 164/361 [02:34<03:14,  1.02it/s]\u001b[A\n",
            "Iteration:  46% 165/361 [02:35<03:13,  1.02it/s]\u001b[A\n",
            "Iteration:  46% 166/361 [02:36<03:12,  1.01it/s]\u001b[A\n",
            "Iteration:  46% 167/361 [02:37<03:11,  1.01it/s]\u001b[A\n",
            "Iteration:  47% 168/361 [02:37<03:10,  1.01it/s]\u001b[A\n",
            "Iteration:  47% 169/361 [02:38<03:09,  1.01it/s]\u001b[A\n",
            "Iteration:  47% 170/361 [02:39<03:09,  1.01it/s]\u001b[A\n",
            "Iteration:  47% 171/361 [02:40<03:08,  1.01it/s]\u001b[A\n",
            "Iteration:  48% 172/361 [02:41<03:07,  1.01it/s]\u001b[A\n",
            "Iteration:  48% 173/361 [02:42<03:06,  1.01it/s]\u001b[A\n",
            "Iteration:  48% 174/361 [02:43<03:05,  1.01it/s]\u001b[A\n",
            "Iteration:  48% 175/361 [02:44<03:05,  1.01it/s]\u001b[A\n",
            "Iteration:  49% 176/361 [02:45<03:04,  1.01it/s]\u001b[A\n",
            "Iteration:  49% 177/361 [02:46<03:03,  1.00it/s]\u001b[A\n",
            "Iteration:  49% 178/361 [02:47<03:02,  1.00it/s]\u001b[A\n",
            "Iteration:  50% 179/361 [02:48<03:01,  1.00it/s]\u001b[A\n",
            "Iteration:  50% 180/361 [02:49<03:00,  1.00it/s]\u001b[A\n",
            "Iteration:  50% 181/361 [02:50<02:59,  1.00it/s]\u001b[A\n",
            "Iteration:  50% 182/361 [02:51<02:58,  1.00it/s]\u001b[A\n",
            "Iteration:  51% 183/361 [02:52<02:57,  1.00it/s]\u001b[A\n",
            "Iteration:  51% 184/361 [02:53<02:56,  1.00it/s]\u001b[A\n",
            "Iteration:  51% 185/361 [02:54<02:55,  1.00it/s]\u001b[A\n",
            "Iteration:  52% 186/361 [02:55<02:54,  1.00it/s]\u001b[A\n",
            "Iteration:  52% 187/361 [02:56<02:53,  1.00it/s]\u001b[A\n",
            "Iteration:  52% 188/361 [02:57<02:52,  1.00it/s]\u001b[A\n",
            "Iteration:  52% 189/361 [02:58<02:51,  1.00it/s]\u001b[A\n",
            "Iteration:  53% 190/361 [02:59<02:50,  1.00it/s]\u001b[A\n",
            "Iteration:  53% 191/361 [03:00<02:49,  1.00it/s]\u001b[A\n",
            "Iteration:  53% 192/361 [03:01<02:48,  1.00it/s]\u001b[A\n",
            "Iteration:  53% 193/361 [03:02<02:47,  1.00it/s]\u001b[A\n",
            "Iteration:  54% 194/361 [03:03<02:46,  1.00it/s]\u001b[A\n",
            "Iteration:  54% 195/361 [03:04<02:45,  1.00it/s]\u001b[A\n",
            "Iteration:  54% 196/361 [03:05<02:44,  1.00it/s]\u001b[A\n",
            "Iteration:  55% 197/361 [03:06<02:43,  1.00it/s]\u001b[A\n",
            "Iteration:  55% 198/361 [03:07<02:42,  1.00it/s]\u001b[A\n",
            "Iteration:  55% 199/361 [03:08<02:41,  1.00it/s]\u001b[A\n",
            "Iteration:  55% 200/361 [03:09<02:40,  1.00it/s]\u001b[A\n",
            "Iteration:  56% 201/361 [03:10<02:39,  1.00it/s]\u001b[A\n",
            "Iteration:  56% 202/361 [03:11<02:39,  1.00s/it]\u001b[A\n",
            "Iteration:  56% 203/361 [03:12<02:38,  1.00s/it]\u001b[A\n",
            "Iteration:  57% 204/361 [03:13<02:36,  1.00it/s]\u001b[A\n",
            "Iteration:  57% 205/361 [03:14<02:35,  1.00it/s]\u001b[A\n",
            "Iteration:  57% 206/361 [03:15<02:35,  1.00s/it]\u001b[A\n",
            "Iteration:  57% 207/361 [03:16<02:34,  1.01s/it]\u001b[A\n",
            "Iteration:  58% 208/361 [03:17<02:33,  1.00s/it]\u001b[A\n",
            "Iteration:  58% 209/361 [03:18<02:32,  1.01s/it]\u001b[A\n",
            "Iteration:  58% 210/361 [03:19<02:32,  1.01s/it]\u001b[A\n",
            "Iteration:  58% 211/361 [03:20<02:30,  1.01s/it]\u001b[A\n",
            "Iteration:  59% 212/361 [03:21<02:30,  1.01s/it]\u001b[A\n",
            "Iteration:  59% 213/361 [03:22<02:29,  1.01s/it]\u001b[A\n",
            "Iteration:  59% 214/361 [03:23<02:28,  1.01s/it]\u001b[A\n",
            "Iteration:  60% 215/361 [03:25<02:27,  1.01s/it]\u001b[A\n",
            "Iteration:  60% 216/361 [03:26<02:27,  1.01s/it]\u001b[A\n",
            "Iteration:  60% 217/361 [03:27<02:25,  1.01s/it]\u001b[A\n",
            "Iteration:  60% 218/361 [03:28<02:25,  1.02s/it]\u001b[A\n",
            "Iteration:  61% 219/361 [03:29<02:24,  1.01s/it]\u001b[A\n",
            "Iteration:  61% 220/361 [03:30<02:23,  1.02s/it]\u001b[A\n",
            "Iteration:  61% 221/361 [03:31<02:22,  1.02s/it]\u001b[A\n",
            "Iteration:  61% 222/361 [03:32<02:21,  1.02s/it]\u001b[A\n",
            "Iteration:  62% 223/361 [03:33<02:20,  1.02s/it]\u001b[A\n",
            "Iteration:  62% 224/361 [03:34<02:19,  1.02s/it]\u001b[A\n",
            "Iteration:  62% 225/361 [03:35<02:18,  1.02s/it]\u001b[A\n",
            "Iteration:  63% 226/361 [03:36<02:17,  1.02s/it]\u001b[A\n",
            "Iteration:  63% 227/361 [03:37<02:16,  1.02s/it]\u001b[A\n",
            "Iteration:  63% 228/361 [03:38<02:15,  1.02s/it]\u001b[A\n",
            "Iteration:  63% 229/361 [03:39<02:14,  1.02s/it]\u001b[A\n",
            "Iteration:  64% 230/361 [03:40<02:13,  1.02s/it]\u001b[A\n",
            "Iteration:  64% 231/361 [03:41<02:12,  1.02s/it]\u001b[A\n",
            "Iteration:  64% 232/361 [03:42<02:11,  1.02s/it]\u001b[A\n",
            "Iteration:  65% 233/361 [03:43<02:10,  1.02s/it]\u001b[A\n",
            "Iteration:  65% 234/361 [03:44<02:09,  1.02s/it]\u001b[A\n",
            "Iteration:  65% 235/361 [03:45<02:08,  1.02s/it]\u001b[A\n",
            "Iteration:  65% 236/361 [03:46<02:07,  1.02s/it]\u001b[A\n",
            "Iteration:  66% 237/361 [03:47<02:05,  1.02s/it]\u001b[A\n",
            "Iteration:  66% 238/361 [03:48<02:04,  1.02s/it]\u001b[A\n",
            "Iteration:  66% 239/361 [03:49<02:03,  1.02s/it]\u001b[A\n",
            "Iteration:  66% 240/361 [03:50<02:02,  1.02s/it]\u001b[A\n",
            "Iteration:  67% 241/361 [03:51<02:01,  1.02s/it]\u001b[A\n",
            "Iteration:  67% 242/361 [03:52<02:00,  1.02s/it]\u001b[A\n",
            "Iteration:  67% 243/361 [03:53<01:59,  1.02s/it]\u001b[A\n",
            "Iteration:  68% 244/361 [03:54<01:58,  1.02s/it]\u001b[A\n",
            "Iteration:  68% 245/361 [03:55<01:57,  1.02s/it]\u001b[A\n",
            "Iteration:  68% 246/361 [03:56<01:56,  1.02s/it]\u001b[A\n",
            "Iteration:  68% 247/361 [03:57<01:55,  1.02s/it]\u001b[A\n",
            "Iteration:  69% 248/361 [03:58<01:54,  1.02s/it]\u001b[A\n",
            "Iteration:  69% 249/361 [03:59<01:53,  1.02s/it]\u001b[A\n",
            "Iteration:  69% 250/361 [04:00<01:52,  1.02s/it]\u001b[A\n",
            "Iteration:  70% 251/361 [04:01<01:51,  1.02s/it]\u001b[A\n",
            "Iteration:  70% 252/361 [04:02<01:50,  1.02s/it]\u001b[A\n",
            "Iteration:  70% 253/361 [04:03<01:49,  1.02s/it]\u001b[A\n",
            "Iteration:  70% 254/361 [04:04<01:48,  1.02s/it]\u001b[A\n",
            "Iteration:  71% 255/361 [04:05<01:47,  1.02s/it]\u001b[A\n",
            "Iteration:  71% 256/361 [04:06<01:46,  1.02s/it]\u001b[A\n",
            "Iteration:  71% 257/361 [04:07<01:45,  1.02s/it]\u001b[A\n",
            "Iteration:  71% 258/361 [04:08<01:44,  1.02s/it]\u001b[A\n",
            "Iteration:  72% 259/361 [04:09<01:43,  1.02s/it]\u001b[A\n",
            "Iteration:  72% 260/361 [04:10<01:42,  1.02s/it]\u001b[A\n",
            "Iteration:  72% 261/361 [04:11<01:41,  1.02s/it]\u001b[A\n",
            "Iteration:  73% 262/361 [04:12<01:40,  1.02s/it]\u001b[A\n",
            "Iteration:  73% 263/361 [04:13<01:39,  1.02s/it]\u001b[A\n",
            "Iteration:  73% 264/361 [04:14<01:38,  1.02s/it]\u001b[A\n",
            "Iteration:  73% 265/361 [04:15<01:37,  1.02s/it]\u001b[A\n",
            "Iteration:  74% 266/361 [04:16<01:36,  1.02s/it]\u001b[A\n",
            "Iteration:  74% 267/361 [04:17<01:36,  1.02s/it]\u001b[A\n",
            "Iteration:  74% 268/361 [04:18<01:34,  1.02s/it]\u001b[A\n",
            "Iteration:  75% 269/361 [04:19<01:34,  1.03s/it]\u001b[A\n",
            "Iteration:  75% 270/361 [04:20<01:33,  1.03s/it]\u001b[A\n",
            "Iteration:  75% 271/361 [04:21<01:32,  1.03s/it]\u001b[A\n",
            "Iteration:  75% 272/361 [04:22<01:31,  1.02s/it]\u001b[A\n",
            "Iteration:  76% 273/361 [04:24<01:30,  1.03s/it]\u001b[A\n",
            "Iteration:  76% 274/361 [04:25<01:29,  1.02s/it]\u001b[A\n",
            "Iteration:  76% 275/361 [04:26<01:28,  1.03s/it]\u001b[A\n",
            "Iteration:  76% 276/361 [04:27<01:27,  1.03s/it]\u001b[A\n",
            "Iteration:  77% 277/361 [04:28<01:26,  1.03s/it]\u001b[A\n",
            "Iteration:  77% 278/361 [04:29<01:25,  1.03s/it]\u001b[A\n",
            "Iteration:  77% 279/361 [04:30<01:24,  1.03s/it]\u001b[A\n",
            "Iteration:  78% 280/361 [04:31<01:23,  1.03s/it]\u001b[A\n",
            "Iteration:  78% 281/361 [04:32<01:22,  1.03s/it]\u001b[A\n",
            "Iteration:  78% 282/361 [04:33<01:21,  1.03s/it]\u001b[A\n",
            "Iteration:  78% 283/361 [04:34<01:20,  1.03s/it]\u001b[A\n",
            "Iteration:  79% 284/361 [04:35<01:19,  1.04s/it]\u001b[A\n",
            "Iteration:  79% 285/361 [04:36<01:18,  1.04s/it]\u001b[A\n",
            "Iteration:  79% 286/361 [04:37<01:17,  1.04s/it]\u001b[A\n",
            "Iteration:  80% 287/361 [04:38<01:16,  1.04s/it]\u001b[A\n",
            "Iteration:  80% 288/361 [04:39<01:15,  1.04s/it]\u001b[A\n",
            "Iteration:  80% 289/361 [04:40<01:14,  1.04s/it]\u001b[A\n",
            "Iteration:  80% 290/361 [04:41<01:13,  1.04s/it]\u001b[A\n",
            "Iteration:  81% 291/361 [04:42<01:12,  1.04s/it]\u001b[A\n",
            "Iteration:  81% 292/361 [04:43<01:11,  1.04s/it]\u001b[A\n",
            "Iteration:  81% 293/361 [04:44<01:10,  1.04s/it]\u001b[A\n",
            "Iteration:  81% 294/361 [04:45<01:09,  1.04s/it]\u001b[A\n",
            "Iteration:  82% 295/361 [04:46<01:08,  1.04s/it]\u001b[A\n",
            "Iteration:  82% 296/361 [04:47<01:07,  1.04s/it]\u001b[A\n",
            "Iteration:  82% 297/361 [04:48<01:06,  1.04s/it]\u001b[A\n",
            "Iteration:  83% 298/361 [04:49<01:05,  1.04s/it]\u001b[A\n",
            "Iteration:  83% 299/361 [04:50<01:04,  1.04s/it]\u001b[A\n",
            "Iteration:  83% 300/361 [04:51<01:03,  1.04s/it]\u001b[A\n",
            "Iteration:  83% 301/361 [04:52<01:02,  1.04s/it]\u001b[A\n",
            "Iteration:  84% 302/361 [04:54<01:01,  1.04s/it]\u001b[A\n",
            "Iteration:  84% 303/361 [04:55<01:00,  1.04s/it]\u001b[A\n",
            "Iteration:  84% 304/361 [04:56<00:59,  1.04s/it]\u001b[A\n",
            "Iteration:  84% 305/361 [04:57<00:58,  1.04s/it]\u001b[A\n",
            "Iteration:  85% 306/361 [04:58<00:56,  1.04s/it]\u001b[A\n",
            "Iteration:  85% 307/361 [04:59<00:55,  1.04s/it]\u001b[A\n",
            "Iteration:  85% 308/361 [05:00<00:54,  1.04s/it]\u001b[A\n",
            "Iteration:  86% 309/361 [05:01<00:53,  1.04s/it]\u001b[A\n",
            "Iteration:  86% 310/361 [05:02<00:52,  1.04s/it]\u001b[A\n",
            "Iteration:  86% 311/361 [05:03<00:51,  1.04s/it]\u001b[A\n",
            "Iteration:  86% 312/361 [05:04<00:50,  1.03s/it]\u001b[A\n",
            "Iteration:  87% 313/361 [05:05<00:49,  1.03s/it]\u001b[A\n",
            "Iteration:  87% 314/361 [05:06<00:48,  1.04s/it]\u001b[A\n",
            "Iteration:  87% 315/361 [05:07<00:47,  1.04s/it]\u001b[A\n",
            "Iteration:  88% 316/361 [05:08<00:46,  1.03s/it]\u001b[A\n",
            "Iteration:  88% 317/361 [05:09<00:45,  1.03s/it]\u001b[A\n",
            "Iteration:  88% 318/361 [05:10<00:44,  1.03s/it]\u001b[A\n",
            "Iteration:  88% 319/361 [05:11<00:43,  1.04s/it]\u001b[A\n",
            "Iteration:  89% 320/361 [05:12<00:42,  1.04s/it]\u001b[A\n",
            "Iteration:  89% 321/361 [05:13<00:41,  1.04s/it]\u001b[A\n",
            "Iteration:  89% 322/361 [05:14<00:40,  1.04s/it]\u001b[A\n",
            "Iteration:  89% 323/361 [05:15<00:39,  1.04s/it]\u001b[A\n",
            "Iteration:  90% 324/361 [05:16<00:38,  1.04s/it]\u001b[A\n",
            "Iteration:  90% 325/361 [05:17<00:37,  1.04s/it]\u001b[A\n",
            "Iteration:  90% 326/361 [05:18<00:36,  1.04s/it]\u001b[A\n",
            "Iteration:  91% 327/361 [05:19<00:35,  1.04s/it]\u001b[A\n",
            "Iteration:  91% 328/361 [05:20<00:34,  1.04s/it]\u001b[A\n",
            "Iteration:  91% 329/361 [05:22<00:33,  1.04s/it]\u001b[A\n",
            "Iteration:  91% 330/361 [05:23<00:32,  1.04s/it]\u001b[A\n",
            "Iteration:  92% 331/361 [05:24<00:31,  1.04s/it]\u001b[A\n",
            "Iteration:  92% 332/361 [05:25<00:30,  1.04s/it]\u001b[A\n",
            "Iteration:  92% 333/361 [05:26<00:29,  1.04s/it]\u001b[A\n",
            "Iteration:  93% 334/361 [05:27<00:27,  1.04s/it]\u001b[A\n",
            "Iteration:  93% 335/361 [05:28<00:26,  1.04s/it]\u001b[A\n",
            "Iteration:  93% 336/361 [05:29<00:25,  1.04s/it]\u001b[A\n",
            "Iteration:  93% 337/361 [05:30<00:24,  1.04s/it]\u001b[A\n",
            "Iteration:  94% 338/361 [05:31<00:23,  1.04s/it]\u001b[A\n",
            "Iteration:  94% 339/361 [05:32<00:22,  1.04s/it]\u001b[A\n",
            "Iteration:  94% 340/361 [05:33<00:21,  1.04s/it]\u001b[A\n",
            "Iteration:  94% 341/361 [05:34<00:20,  1.04s/it]\u001b[A\n",
            "Iteration:  95% 342/361 [05:35<00:19,  1.04s/it]\u001b[A\n",
            "Iteration:  95% 343/361 [05:36<00:18,  1.04s/it]\u001b[A\n",
            "Iteration:  95% 344/361 [05:37<00:17,  1.04s/it]\u001b[A\n",
            "Iteration:  96% 345/361 [05:38<00:16,  1.04s/it]\u001b[A\n",
            "Iteration:  96% 346/361 [05:39<00:15,  1.04s/it]\u001b[A\n",
            "Iteration:  96% 347/361 [05:40<00:14,  1.04s/it]\u001b[A\n",
            "Iteration:  96% 348/361 [05:41<00:13,  1.04s/it]\u001b[A\n",
            "Iteration:  97% 349/361 [05:42<00:12,  1.04s/it]\u001b[A\n",
            "Iteration:  97% 350/361 [05:43<00:11,  1.04s/it]\u001b[A\n",
            "Iteration:  97% 351/361 [05:44<00:10,  1.04s/it]\u001b[A\n",
            "Iteration:  98% 352/361 [05:45<00:09,  1.04s/it]\u001b[A\n",
            "Iteration:  98% 353/361 [05:46<00:08,  1.04s/it]\u001b[A\n",
            "Iteration:  98% 354/361 [05:47<00:07,  1.04s/it]\u001b[A\n",
            "Iteration:  98% 355/361 [05:48<00:06,  1.04s/it]\u001b[A\n",
            "Iteration:  99% 356/361 [05:49<00:05,  1.04s/it]\u001b[A\n",
            "Iteration:  99% 357/361 [05:51<00:04,  1.04s/it]\u001b[A\n",
            "Iteration:  99% 358/361 [05:52<00:03,  1.04s/it]\u001b[A\n",
            "Iteration:  99% 359/361 [05:53<00:02,  1.04s/it]\u001b[A\n",
            "Iteration: 100% 360/361 [05:54<00:01,  1.04s/it]\u001b[A\n",
            "Iteration: 100% 361/361 [05:55<00:00,  1.02it/s]\n",
            "Epoch:  50% 1/2 [05:55<05:55, 355.21s/it]\n",
            "Iteration:   0% 0/361 [00:00<?, ?it/s]\u001b[A\n",
            "Iteration:   0% 1/361 [00:01<06:19,  1.05s/it]\u001b[A\n",
            "Iteration:   1% 2/361 [00:02<06:18,  1.05s/it]\u001b[A\n",
            "Iteration:   1% 3/361 [00:03<06:15,  1.05s/it]\u001b[A\n",
            "Iteration:   1% 4/361 [00:04<06:15,  1.05s/it]\u001b[A\n",
            "Iteration:   1% 5/361 [00:05<06:12,  1.05s/it]\u001b[A\n",
            "Iteration:   2% 6/361 [00:06<06:12,  1.05s/it]\u001b[A\n",
            "Iteration:   2% 7/361 [00:07<06:10,  1.05s/it]\u001b[A\n",
            "Iteration:   2% 8/361 [00:08<06:10,  1.05s/it]\u001b[A\n",
            "Iteration:   2% 9/361 [00:09<06:09,  1.05s/it]\u001b[A\n",
            "Iteration:   3% 10/361 [00:10<06:09,  1.05s/it]\u001b[A\n",
            "Iteration:   3% 11/361 [00:11<06:08,  1.05s/it]\u001b[A\n",
            "Iteration:   3% 12/361 [00:12<06:06,  1.05s/it]\u001b[A\n",
            "Iteration:   4% 13/361 [00:13<06:04,  1.05s/it]\u001b[A\n",
            "Iteration:   4% 14/361 [00:14<06:04,  1.05s/it]\u001b[A\n",
            "Iteration:   4% 15/361 [00:15<06:03,  1.05s/it]\u001b[A\n",
            "Iteration:   4% 16/361 [00:16<06:02,  1.05s/it]\u001b[A\n",
            "Iteration:   5% 17/361 [00:17<06:01,  1.05s/it]\u001b[A\n",
            "Iteration:   5% 18/361 [00:18<05:59,  1.05s/it]\u001b[A\n",
            "Iteration:   5% 19/361 [00:19<05:59,  1.05s/it]\u001b[A\n",
            "Iteration:   6% 20/361 [00:20<05:57,  1.05s/it]\u001b[A\n",
            "Iteration:   6% 21/361 [00:22<05:57,  1.05s/it]\u001b[A\n",
            "Iteration:   6% 22/361 [00:23<05:56,  1.05s/it]\u001b[A\n",
            "Iteration:   6% 23/361 [00:24<05:54,  1.05s/it]\u001b[A\n",
            "Iteration:   7% 24/361 [00:25<05:54,  1.05s/it]\u001b[A\n",
            "Iteration:   7% 25/361 [00:26<05:54,  1.05s/it]\u001b[A\n",
            "Iteration:   7% 26/361 [00:27<05:53,  1.06s/it]\u001b[A\n",
            "Iteration:   7% 27/361 [00:28<05:51,  1.05s/it]\u001b[A\n",
            "Iteration:   8% 28/361 [00:29<05:50,  1.05s/it]\u001b[A\n",
            "Iteration:   8% 29/361 [00:30<05:49,  1.05s/it]\u001b[A\n",
            "Iteration:   8% 30/361 [00:31<05:49,  1.06s/it]\u001b[A\n",
            "Iteration:   9% 31/361 [00:32<05:48,  1.06s/it]\u001b[A\n",
            "Iteration:   9% 32/361 [00:33<05:47,  1.06s/it]\u001b[A\n",
            "Iteration:   9% 33/361 [00:34<05:46,  1.06s/it]\u001b[A\n",
            "Iteration:   9% 34/361 [00:35<05:45,  1.06s/it]\u001b[A\n",
            "Iteration:  10% 35/361 [00:36<05:44,  1.06s/it]\u001b[A\n",
            "Iteration:  10% 36/361 [00:37<05:43,  1.06s/it]\u001b[A\n",
            "Iteration:  10% 37/361 [00:38<05:42,  1.06s/it]\u001b[A\n",
            "Iteration:  11% 38/361 [00:39<05:41,  1.06s/it]\u001b[A\n",
            "Iteration:  11% 39/361 [00:41<05:40,  1.06s/it]\u001b[A\n",
            "Iteration:  11% 40/361 [00:42<05:39,  1.06s/it]\u001b[A\n",
            "Iteration:  11% 41/361 [00:43<05:38,  1.06s/it]\u001b[A\n",
            "Iteration:  12% 42/361 [00:44<05:37,  1.06s/it]\u001b[A\n",
            "Iteration:  12% 43/361 [00:45<05:36,  1.06s/it]\u001b[A\n",
            "Iteration:  12% 44/361 [00:46<05:35,  1.06s/it]\u001b[A\n",
            "Iteration:  12% 45/361 [00:47<05:34,  1.06s/it]\u001b[A\n",
            "Iteration:  13% 46/361 [00:48<05:33,  1.06s/it]\u001b[A\n",
            "Iteration:  13% 47/361 [00:49<05:31,  1.06s/it]\u001b[A\n",
            "Iteration:  13% 48/361 [00:50<05:30,  1.06s/it]\u001b[A\n",
            "Iteration:  14% 49/361 [00:51<05:29,  1.06s/it]\u001b[A\n",
            "Iteration:  14% 50/361 [00:52<05:28,  1.06s/it]\u001b[A\n",
            "Iteration:  14% 51/361 [00:53<05:26,  1.05s/it]\u001b[A\n",
            "Iteration:  14% 52/361 [00:54<05:25,  1.05s/it]\u001b[A\n",
            "Iteration:  15% 53/361 [00:55<05:24,  1.05s/it]\u001b[A\n",
            "Iteration:  15% 54/361 [00:56<05:23,  1.05s/it]\u001b[A\n",
            "Iteration:  15% 55/361 [00:57<05:23,  1.06s/it]\u001b[A\n",
            "Iteration:  16% 56/361 [00:58<05:21,  1.05s/it]\u001b[A\n",
            "Iteration:  16% 57/361 [01:00<05:19,  1.05s/it]\u001b[A\n",
            "Iteration:  16% 58/361 [01:01<05:18,  1.05s/it]\u001b[A\n",
            "Iteration:  16% 59/361 [01:02<05:18,  1.05s/it]\u001b[A\n",
            "Iteration:  17% 60/361 [01:03<05:16,  1.05s/it]\u001b[A\n",
            "Iteration:  17% 61/361 [01:04<05:15,  1.05s/it]\u001b[A\n",
            "Iteration:  17% 62/361 [01:05<05:14,  1.05s/it]\u001b[A\n",
            "Iteration:  17% 63/361 [01:06<05:13,  1.05s/it]\u001b[A\n",
            "Iteration:  18% 64/361 [01:07<05:11,  1.05s/it]\u001b[A\n",
            "Iteration:  18% 65/361 [01:08<05:11,  1.05s/it]\u001b[A\n",
            "Iteration:  18% 66/361 [01:09<05:10,  1.05s/it]\u001b[A\n",
            "Iteration:  19% 67/361 [01:10<05:10,  1.05s/it]\u001b[A\n",
            "Iteration:  19% 68/361 [01:11<05:09,  1.06s/it]\u001b[A\n",
            "Iteration:  19% 69/361 [01:12<05:08,  1.06s/it]\u001b[A\n",
            "Iteration:  19% 70/361 [01:13<05:06,  1.05s/it]\u001b[A\n",
            "Iteration:  20% 71/361 [01:14<05:06,  1.06s/it]\u001b[A\n",
            "Iteration:  20% 72/361 [01:15<05:04,  1.06s/it]\u001b[A\n",
            "Iteration:  20% 73/361 [01:16<05:03,  1.06s/it]\u001b[A\n",
            "Iteration:  20% 74/361 [01:17<05:01,  1.05s/it]\u001b[A\n",
            "Iteration:  21% 75/361 [01:18<05:01,  1.05s/it]\u001b[A\n",
            "Iteration:  21% 76/361 [01:20<04:59,  1.05s/it]\u001b[A\n",
            "Iteration:  21% 77/361 [01:21<04:57,  1.05s/it]\u001b[A\n",
            "Iteration:  22% 78/361 [01:22<04:56,  1.05s/it]\u001b[A\n",
            "Iteration:  22% 79/361 [01:23<04:55,  1.05s/it]\u001b[A\n",
            "Iteration:  22% 80/361 [01:24<04:53,  1.04s/it]\u001b[A\n",
            "Iteration:  22% 81/361 [01:25<04:53,  1.05s/it]\u001b[A\n",
            "Iteration:  23% 82/361 [01:26<04:51,  1.05s/it]\u001b[A\n",
            "Iteration:  23% 83/361 [01:27<04:51,  1.05s/it]\u001b[A\n",
            "Iteration:  23% 84/361 [01:28<04:49,  1.05s/it]\u001b[A\n",
            "Iteration:  24% 85/361 [01:29<04:48,  1.04s/it]\u001b[A\n",
            "Iteration:  24% 86/361 [01:30<04:46,  1.04s/it]\u001b[A\n",
            "Iteration:  24% 87/361 [01:31<04:46,  1.05s/it]\u001b[A\n",
            "Iteration:  24% 88/361 [01:32<04:45,  1.05s/it]\u001b[A\n",
            "Iteration:  25% 89/361 [01:33<04:43,  1.04s/it]\u001b[A\n",
            "Iteration:  25% 90/361 [01:34<04:44,  1.05s/it]\u001b[A\n",
            "Iteration:  25% 91/361 [01:35<04:43,  1.05s/it]\u001b[A\n",
            "Iteration:  25% 92/361 [01:36<04:41,  1.05s/it]\u001b[A\n",
            "Iteration:  26% 93/361 [01:37<04:41,  1.05s/it]\u001b[A\n",
            "Iteration:  26% 94/361 [01:38<04:39,  1.05s/it]\u001b[A\n",
            "Iteration:  26% 95/361 [01:39<04:39,  1.05s/it]\u001b[A\n",
            "Iteration:  27% 96/361 [01:40<04:38,  1.05s/it]\u001b[A\n",
            "Iteration:  27% 97/361 [01:42<04:36,  1.05s/it]\u001b[A\n",
            "Iteration:  27% 98/361 [01:43<04:35,  1.05s/it]\u001b[A\n",
            "Iteration:  27% 99/361 [01:44<04:34,  1.05s/it]\u001b[A\n",
            "Iteration:  28% 100/361 [01:45<04:33,  1.05s/it]\u001b[A\n",
            "Iteration:  28% 101/361 [01:46<04:32,  1.05s/it]\u001b[A\n",
            "Iteration:  28% 102/361 [01:47<04:31,  1.05s/it]\u001b[A\n",
            "Iteration:  29% 103/361 [01:48<04:29,  1.04s/it]\u001b[A\n",
            "Iteration:  29% 104/361 [01:49<04:29,  1.05s/it]\u001b[A\n",
            "Iteration:  29% 105/361 [01:50<04:27,  1.04s/it]\u001b[A\n",
            "Iteration:  29% 106/361 [01:51<04:26,  1.04s/it]\u001b[A\n",
            "Iteration:  30% 107/361 [01:52<04:25,  1.05s/it]\u001b[A\n",
            "Iteration:  30% 108/361 [01:53<04:23,  1.04s/it]\u001b[A\n",
            "Iteration:  30% 109/361 [01:54<04:23,  1.05s/it]\u001b[A\n",
            "Iteration:  30% 110/361 [01:55<04:23,  1.05s/it]\u001b[A\n",
            "Iteration:  31% 111/361 [01:56<04:21,  1.05s/it]\u001b[A\n",
            "Iteration:  31% 112/361 [01:57<04:21,  1.05s/it]\u001b[A\n",
            "Iteration:  31% 113/361 [01:58<04:20,  1.05s/it]\u001b[A\n",
            "Iteration:  32% 114/361 [01:59<04:18,  1.05s/it]\u001b[A\n",
            "Iteration:  32% 115/361 [02:00<04:18,  1.05s/it]\u001b[A\n",
            "Iteration:  32% 116/361 [02:01<04:16,  1.05s/it]\u001b[A\n",
            "Iteration:  32% 117/361 [02:02<04:15,  1.05s/it]\u001b[A\n",
            "Iteration:  33% 118/361 [02:04<04:13,  1.05s/it]\u001b[A\n",
            "Iteration:  33% 119/361 [02:05<04:13,  1.05s/it]\u001b[A\n",
            "Iteration:  33% 120/361 [02:06<04:12,  1.05s/it]\u001b[A\n",
            "Iteration:  34% 121/361 [02:07<04:11,  1.05s/it]\u001b[A\n",
            "Iteration:  34% 122/361 [02:08<04:09,  1.05s/it]\u001b[A\n",
            "Iteration:  34% 123/361 [02:09<04:08,  1.04s/it]\u001b[A\n",
            "Iteration:  34% 124/361 [02:10<04:07,  1.05s/it]\u001b[A\n",
            "Iteration:  35% 125/361 [02:11<04:07,  1.05s/it]\u001b[A\n",
            "Iteration:  35% 126/361 [02:12<04:05,  1.05s/it]\u001b[A\n",
            "Iteration:  35% 127/361 [02:13<04:05,  1.05s/it]\u001b[A\n",
            "Iteration:  35% 128/361 [02:14<04:03,  1.05s/it]\u001b[A\n",
            "Iteration:  36% 129/361 [02:15<04:01,  1.04s/it]\u001b[A\n",
            "Iteration:  36% 130/361 [02:16<04:01,  1.05s/it]\u001b[A\n",
            "Iteration:  36% 131/361 [02:17<03:59,  1.04s/it]\u001b[A\n",
            "Iteration:  37% 132/361 [02:18<03:59,  1.05s/it]\u001b[A\n",
            "Iteration:  37% 133/361 [02:19<03:59,  1.05s/it]\u001b[A\n",
            "Iteration:  37% 134/361 [02:20<03:58,  1.05s/it]\u001b[A\n",
            "Iteration:  37% 135/361 [02:21<03:56,  1.05s/it]\u001b[A\n",
            "Iteration:  38% 136/361 [02:22<03:56,  1.05s/it]\u001b[A\n",
            "Iteration:  38% 137/361 [02:23<03:54,  1.05s/it]\u001b[A\n",
            "Iteration:  38% 138/361 [02:24<03:54,  1.05s/it]\u001b[A/usr/local/lib/python3.7/dist-packages/torch/optim/lr_scheduler.py:224: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
            "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n",
            "05/14/2021 09:56:00 - INFO - __main__ -   Saving model checkpoint to models/checkpoint-500\n",
            "05/14/2021 09:56:05 - INFO - __main__ -   Saving optimizer and scheduler states to models/checkpoint-500\n",
            "\n",
            "Iteration:  39% 139/361 [02:31<10:21,  2.80s/it]\u001b[A\n",
            "Iteration:  39% 140/361 [02:32<08:22,  2.28s/it]\u001b[A\n",
            "Iteration:  39% 141/361 [02:33<06:57,  1.90s/it]\u001b[A\n",
            "Iteration:  39% 142/361 [02:34<05:59,  1.64s/it]\u001b[A\n",
            "Iteration:  40% 143/361 [02:35<05:18,  1.46s/it]\u001b[A\n",
            "Iteration:  40% 144/361 [02:37<04:49,  1.33s/it]\u001b[A\n",
            "Iteration:  40% 145/361 [02:38<04:28,  1.25s/it]\u001b[A\n",
            "Iteration:  40% 146/361 [02:39<04:14,  1.18s/it]\u001b[A\n",
            "Iteration:  41% 147/361 [02:40<04:03,  1.14s/it]\u001b[A\n",
            "Iteration:  41% 148/361 [02:41<03:56,  1.11s/it]\u001b[A\n",
            "Iteration:  41% 149/361 [02:42<03:50,  1.09s/it]\u001b[A\n",
            "Iteration:  42% 150/361 [02:43<03:46,  1.07s/it]\u001b[A\n",
            "Iteration:  42% 151/361 [02:44<03:43,  1.06s/it]\u001b[A\n",
            "Iteration:  42% 152/361 [02:45<03:40,  1.06s/it]\u001b[A\n",
            "Iteration:  42% 153/361 [02:46<03:38,  1.05s/it]\u001b[A\n",
            "Iteration:  43% 154/361 [02:47<03:36,  1.04s/it]\u001b[A\n",
            "Iteration:  43% 155/361 [02:48<03:34,  1.04s/it]\u001b[A\n",
            "Iteration:  43% 156/361 [02:49<03:33,  1.04s/it]\u001b[A\n",
            "Iteration:  43% 157/361 [02:50<03:32,  1.04s/it]\u001b[A\n",
            "Iteration:  44% 158/361 [02:51<03:32,  1.05s/it]\u001b[A\n",
            "Iteration:  44% 159/361 [02:52<03:32,  1.05s/it]\u001b[A\n",
            "Iteration:  44% 160/361 [02:53<03:31,  1.05s/it]\u001b[A\n",
            "Iteration:  45% 161/361 [02:54<03:31,  1.06s/it]\u001b[A\n",
            "Iteration:  45% 162/361 [02:55<03:29,  1.05s/it]\u001b[A\n",
            "Iteration:  45% 163/361 [02:56<03:28,  1.05s/it]\u001b[A\n",
            "Iteration:  45% 164/361 [02:57<03:28,  1.06s/it]\u001b[A\n",
            "Iteration:  46% 165/361 [02:58<03:27,  1.06s/it]\u001b[A\n",
            "Iteration:  46% 166/361 [03:00<03:26,  1.06s/it]\u001b[A\n",
            "Iteration:  46% 167/361 [03:01<03:25,  1.06s/it]\u001b[A\n",
            "Iteration:  47% 168/361 [03:02<03:24,  1.06s/it]\u001b[A\n",
            "Iteration:  47% 169/361 [03:03<03:23,  1.06s/it]\u001b[A\n",
            "Iteration:  47% 170/361 [03:04<03:22,  1.06s/it]\u001b[A\n",
            "Iteration:  47% 171/361 [03:05<03:20,  1.06s/it]\u001b[A\n",
            "Iteration:  48% 172/361 [03:06<03:19,  1.06s/it]\u001b[A\n",
            "Iteration:  48% 173/361 [03:07<03:18,  1.05s/it]\u001b[A\n",
            "Iteration:  48% 174/361 [03:08<03:17,  1.06s/it]\u001b[A\n",
            "Iteration:  48% 175/361 [03:09<03:16,  1.06s/it]\u001b[A\n",
            "Iteration:  49% 176/361 [03:10<03:15,  1.06s/it]\u001b[A\n",
            "Iteration:  49% 177/361 [03:11<03:14,  1.06s/it]\u001b[A\n",
            "Iteration:  49% 178/361 [03:12<03:13,  1.06s/it]\u001b[A\n",
            "Iteration:  50% 179/361 [03:13<03:12,  1.06s/it]\u001b[A\n",
            "Iteration:  50% 180/361 [03:14<03:11,  1.06s/it]\u001b[A\n",
            "Iteration:  50% 181/361 [03:15<03:10,  1.06s/it]\u001b[A\n",
            "Iteration:  50% 182/361 [03:16<03:09,  1.06s/it]\u001b[A\n",
            "Iteration:  51% 183/361 [03:18<03:08,  1.06s/it]\u001b[A\n",
            "Iteration:  51% 184/361 [03:19<03:06,  1.05s/it]\u001b[A\n",
            "Iteration:  51% 185/361 [03:20<03:05,  1.06s/it]\u001b[A\n",
            "Iteration:  52% 186/361 [03:21<03:04,  1.06s/it]\u001b[A\n",
            "Iteration:  52% 187/361 [03:22<03:03,  1.05s/it]\u001b[A\n",
            "Iteration:  52% 188/361 [03:23<03:02,  1.05s/it]\u001b[A\n",
            "Iteration:  52% 189/361 [03:24<03:01,  1.05s/it]\u001b[A\n",
            "Iteration:  53% 190/361 [03:25<03:00,  1.05s/it]\u001b[A\n",
            "Iteration:  53% 191/361 [03:26<02:59,  1.05s/it]\u001b[A\n",
            "Iteration:  53% 192/361 [03:27<02:58,  1.05s/it]\u001b[A\n",
            "Iteration:  53% 193/361 [03:28<02:56,  1.05s/it]\u001b[A\n",
            "Iteration:  54% 194/361 [03:29<02:55,  1.05s/it]\u001b[A\n",
            "Iteration:  54% 195/361 [03:30<02:54,  1.05s/it]\u001b[A\n",
            "Iteration:  54% 196/361 [03:31<02:52,  1.05s/it]\u001b[A\n",
            "Iteration:  55% 197/361 [03:32<02:52,  1.05s/it]\u001b[A\n",
            "Iteration:  55% 198/361 [03:33<02:51,  1.05s/it]\u001b[A\n",
            "Iteration:  55% 199/361 [03:34<02:49,  1.05s/it]\u001b[A\n",
            "Iteration:  55% 200/361 [03:35<02:48,  1.04s/it]\u001b[A\n",
            "Iteration:  56% 201/361 [03:36<02:46,  1.04s/it]\u001b[A\n",
            "Iteration:  56% 202/361 [03:37<02:45,  1.04s/it]\u001b[A\n",
            "Iteration:  56% 203/361 [03:38<02:44,  1.04s/it]\u001b[A\n",
            "Iteration:  57% 204/361 [03:40<02:43,  1.04s/it]\u001b[A\n",
            "Iteration:  57% 205/361 [03:41<02:42,  1.04s/it]\u001b[A\n",
            "Iteration:  57% 206/361 [03:42<02:40,  1.04s/it]\u001b[A\n",
            "Iteration:  57% 207/361 [03:43<02:39,  1.04s/it]\u001b[A\n",
            "Iteration:  58% 208/361 [03:44<02:38,  1.04s/it]\u001b[A\n",
            "Iteration:  58% 209/361 [03:45<02:37,  1.04s/it]\u001b[A\n",
            "Iteration:  58% 210/361 [03:46<02:36,  1.04s/it]\u001b[A\n",
            "Iteration:  58% 211/361 [03:47<02:35,  1.04s/it]\u001b[A\n",
            "Iteration:  59% 212/361 [03:48<02:34,  1.04s/it]\u001b[A\n",
            "Iteration:  59% 213/361 [03:49<02:33,  1.04s/it]\u001b[A\n",
            "Iteration:  59% 214/361 [03:50<02:32,  1.04s/it]\u001b[A\n",
            "Iteration:  60% 215/361 [03:51<02:31,  1.04s/it]\u001b[A\n",
            "Iteration:  60% 216/361 [03:52<02:30,  1.04s/it]\u001b[A\n",
            "Iteration:  60% 217/361 [03:53<02:29,  1.04s/it]\u001b[A\n",
            "Iteration:  60% 218/361 [03:54<02:28,  1.04s/it]\u001b[A\n",
            "Iteration:  61% 219/361 [03:55<02:27,  1.04s/it]\u001b[A\n",
            "Iteration:  61% 220/361 [03:56<02:26,  1.04s/it]\u001b[A\n",
            "Iteration:  61% 221/361 [03:57<02:25,  1.04s/it]\u001b[A\n",
            "Iteration:  61% 222/361 [03:58<02:23,  1.04s/it]\u001b[A\n",
            "Iteration:  62% 223/361 [03:59<02:22,  1.04s/it]\u001b[A\n",
            "Iteration:  62% 224/361 [04:00<02:21,  1.04s/it]\u001b[A\n",
            "Iteration:  62% 225/361 [04:01<02:20,  1.04s/it]\u001b[A\n",
            "Iteration:  63% 226/361 [04:02<02:19,  1.04s/it]\u001b[A\n",
            "Iteration:  63% 227/361 [04:03<02:18,  1.04s/it]\u001b[A\n",
            "Iteration:  63% 228/361 [04:04<02:17,  1.04s/it]\u001b[A\n",
            "Iteration:  63% 229/361 [04:05<02:16,  1.04s/it]\u001b[A\n",
            "Iteration:  64% 230/361 [04:06<02:15,  1.04s/it]\u001b[A\n",
            "Iteration:  64% 231/361 [04:08<02:14,  1.04s/it]\u001b[A\n",
            "Iteration:  64% 232/361 [04:09<02:13,  1.04s/it]\u001b[A\n",
            "Iteration:  65% 233/361 [04:10<02:12,  1.04s/it]\u001b[A\n",
            "Iteration:  65% 234/361 [04:11<02:11,  1.04s/it]\u001b[A\n",
            "Iteration:  65% 235/361 [04:12<02:10,  1.04s/it]\u001b[A\n",
            "Iteration:  65% 236/361 [04:13<02:09,  1.04s/it]\u001b[A\n",
            "Iteration:  66% 237/361 [04:14<02:08,  1.04s/it]\u001b[A\n",
            "Iteration:  66% 238/361 [04:15<02:07,  1.04s/it]\u001b[A\n",
            "Iteration:  66% 239/361 [04:16<02:06,  1.04s/it]\u001b[A\n",
            "Iteration:  66% 240/361 [04:17<02:05,  1.04s/it]\u001b[A\n",
            "Iteration:  67% 241/361 [04:18<02:04,  1.04s/it]\u001b[A\n",
            "Iteration:  67% 242/361 [04:19<02:03,  1.04s/it]\u001b[A\n",
            "Iteration:  67% 243/361 [04:20<02:02,  1.04s/it]\u001b[A\n",
            "Iteration:  68% 244/361 [04:21<02:01,  1.04s/it]\u001b[A\n",
            "Iteration:  68% 245/361 [04:22<02:00,  1.04s/it]\u001b[A\n",
            "Iteration:  68% 246/361 [04:23<01:59,  1.04s/it]\u001b[A\n",
            "Iteration:  68% 247/361 [04:24<01:58,  1.04s/it]\u001b[A\n",
            "Iteration:  69% 248/361 [04:25<01:57,  1.04s/it]\u001b[A\n",
            "Iteration:  69% 249/361 [04:26<01:56,  1.04s/it]\u001b[A\n",
            "Iteration:  69% 250/361 [04:27<01:55,  1.04s/it]\u001b[A\n",
            "Iteration:  70% 251/361 [04:28<01:54,  1.04s/it]\u001b[A\n",
            "Iteration:  70% 252/361 [04:29<01:52,  1.04s/it]\u001b[A\n",
            "Iteration:  70% 253/361 [04:30<01:51,  1.04s/it]\u001b[A\n",
            "Iteration:  70% 254/361 [04:31<01:50,  1.04s/it]\u001b[A\n",
            "Iteration:  71% 255/361 [04:32<01:49,  1.04s/it]\u001b[A\n",
            "Iteration:  71% 256/361 [04:33<01:48,  1.04s/it]\u001b[A\n",
            "Iteration:  71% 257/361 [04:34<01:47,  1.04s/it]\u001b[A\n",
            "Iteration:  71% 258/361 [04:35<01:46,  1.04s/it]\u001b[A\n",
            "Iteration:  72% 259/361 [04:37<01:45,  1.04s/it]\u001b[A\n",
            "Iteration:  72% 260/361 [04:38<01:44,  1.04s/it]\u001b[A\n",
            "Iteration:  72% 261/361 [04:39<01:43,  1.04s/it]\u001b[A\n",
            "Iteration:  73% 262/361 [04:40<01:42,  1.04s/it]\u001b[A\n",
            "Iteration:  73% 263/361 [04:41<01:41,  1.04s/it]\u001b[A\n",
            "Iteration:  73% 264/361 [04:42<01:40,  1.04s/it]\u001b[A\n",
            "Iteration:  73% 265/361 [04:43<01:39,  1.04s/it]\u001b[A\n",
            "Iteration:  74% 266/361 [04:44<01:39,  1.04s/it]\u001b[A\n",
            "Iteration:  74% 267/361 [04:45<01:37,  1.04s/it]\u001b[A\n",
            "Iteration:  74% 268/361 [04:46<01:36,  1.04s/it]\u001b[A\n",
            "Iteration:  75% 269/361 [04:47<01:35,  1.04s/it]\u001b[A\n",
            "Iteration:  75% 270/361 [04:48<01:34,  1.04s/it]\u001b[A\n",
            "Iteration:  75% 271/361 [04:49<01:33,  1.04s/it]\u001b[A\n",
            "Iteration:  75% 272/361 [04:50<01:32,  1.04s/it]\u001b[A\n",
            "Iteration:  76% 273/361 [04:51<01:31,  1.04s/it]\u001b[A\n",
            "Iteration:  76% 274/361 [04:52<01:30,  1.04s/it]\u001b[A\n",
            "Iteration:  76% 275/361 [04:53<01:29,  1.04s/it]\u001b[A\n",
            "Iteration:  76% 276/361 [04:54<01:28,  1.04s/it]\u001b[A\n",
            "Iteration:  77% 277/361 [04:55<01:27,  1.04s/it]\u001b[A\n",
            "Iteration:  77% 278/361 [04:56<01:26,  1.04s/it]\u001b[A\n",
            "Iteration:  77% 279/361 [04:57<01:25,  1.04s/it]\u001b[A\n",
            "Iteration:  78% 280/361 [04:58<01:24,  1.04s/it]\u001b[A\n",
            "Iteration:  78% 281/361 [04:59<01:23,  1.04s/it]\u001b[A\n",
            "Iteration:  78% 282/361 [05:00<01:22,  1.04s/it]\u001b[A\n",
            "Iteration:  78% 283/361 [05:01<01:21,  1.04s/it]\u001b[A\n",
            "Iteration:  79% 284/361 [05:03<01:20,  1.04s/it]\u001b[A\n",
            "Iteration:  79% 285/361 [05:04<01:19,  1.04s/it]\u001b[A\n",
            "Iteration:  79% 286/361 [05:05<01:18,  1.04s/it]\u001b[A\n",
            "Iteration:  80% 287/361 [05:06<01:17,  1.04s/it]\u001b[A\n",
            "Iteration:  80% 288/361 [05:07<01:15,  1.04s/it]\u001b[A\n",
            "Iteration:  80% 289/361 [05:08<01:14,  1.04s/it]\u001b[A\n",
            "Iteration:  80% 290/361 [05:09<01:13,  1.04s/it]\u001b[A\n",
            "Iteration:  81% 291/361 [05:10<01:12,  1.04s/it]\u001b[A\n",
            "Iteration:  81% 292/361 [05:11<01:11,  1.04s/it]\u001b[A\n",
            "Iteration:  81% 293/361 [05:12<01:10,  1.04s/it]\u001b[A\n",
            "Iteration:  81% 294/361 [05:13<01:09,  1.04s/it]\u001b[A\n",
            "Iteration:  82% 295/361 [05:14<01:08,  1.04s/it]\u001b[A\n",
            "Iteration:  82% 296/361 [05:15<01:07,  1.04s/it]\u001b[A\n",
            "Iteration:  82% 297/361 [05:16<01:06,  1.04s/it]\u001b[A\n",
            "Iteration:  83% 298/361 [05:17<01:05,  1.04s/it]\u001b[A\n",
            "Iteration:  83% 299/361 [05:18<01:04,  1.04s/it]\u001b[A\n",
            "Iteration:  83% 300/361 [05:19<01:03,  1.04s/it]\u001b[A\n",
            "Iteration:  83% 301/361 [05:20<01:02,  1.04s/it]\u001b[A\n",
            "Iteration:  84% 302/361 [05:21<01:01,  1.04s/it]\u001b[A\n",
            "Iteration:  84% 303/361 [05:22<01:00,  1.04s/it]\u001b[A\n",
            "Iteration:  84% 304/361 [05:23<00:59,  1.04s/it]\u001b[A\n",
            "Iteration:  84% 305/361 [05:24<00:58,  1.04s/it]\u001b[A\n",
            "Iteration:  85% 306/361 [05:25<00:57,  1.04s/it]\u001b[A\n",
            "Iteration:  85% 307/361 [05:26<00:56,  1.04s/it]\u001b[A\n",
            "Iteration:  85% 308/361 [05:27<00:55,  1.04s/it]\u001b[A\n",
            "Iteration:  86% 309/361 [05:29<00:54,  1.04s/it]\u001b[A\n",
            "Iteration:  86% 310/361 [05:30<00:53,  1.04s/it]\u001b[A\n",
            "Iteration:  86% 311/361 [05:31<00:52,  1.04s/it]\u001b[A\n",
            "Iteration:  86% 312/361 [05:32<00:51,  1.05s/it]\u001b[A\n",
            "Iteration:  87% 313/361 [05:33<00:50,  1.04s/it]\u001b[A\n",
            "Iteration:  87% 314/361 [05:34<00:49,  1.05s/it]\u001b[A\n",
            "Iteration:  87% 315/361 [05:35<00:48,  1.04s/it]\u001b[A\n",
            "Iteration:  88% 316/361 [05:36<00:47,  1.05s/it]\u001b[A\n",
            "Iteration:  88% 317/361 [05:37<00:45,  1.04s/it]\u001b[A\n",
            "Iteration:  88% 318/361 [05:38<00:45,  1.05s/it]\u001b[A\n",
            "Iteration:  88% 319/361 [05:39<00:43,  1.04s/it]\u001b[A\n",
            "Iteration:  89% 320/361 [05:40<00:42,  1.05s/it]\u001b[A\n",
            "Iteration:  89% 321/361 [05:41<00:41,  1.05s/it]\u001b[A\n",
            "Iteration:  89% 322/361 [05:42<00:40,  1.05s/it]\u001b[A\n",
            "Iteration:  89% 323/361 [05:43<00:39,  1.04s/it]\u001b[A\n",
            "Iteration:  90% 324/361 [05:44<00:38,  1.04s/it]\u001b[A\n",
            "Iteration:  90% 325/361 [05:45<00:37,  1.04s/it]\u001b[A\n",
            "Iteration:  90% 326/361 [05:46<00:36,  1.04s/it]\u001b[A\n",
            "Iteration:  91% 327/361 [05:47<00:35,  1.04s/it]\u001b[A\n",
            "Iteration:  91% 328/361 [05:48<00:34,  1.04s/it]\u001b[A\n",
            "Iteration:  91% 329/361 [05:49<00:33,  1.04s/it]\u001b[A\n",
            "Iteration:  91% 330/361 [05:50<00:32,  1.04s/it]\u001b[A\n",
            "Iteration:  92% 331/361 [05:51<00:31,  1.04s/it]\u001b[A\n",
            "Iteration:  92% 332/361 [05:53<00:30,  1.04s/it]\u001b[A\n",
            "Iteration:  92% 333/361 [05:54<00:29,  1.04s/it]\u001b[A\n",
            "Iteration:  93% 334/361 [05:55<00:28,  1.04s/it]\u001b[A\n",
            "Iteration:  93% 335/361 [05:56<00:27,  1.04s/it]\u001b[A\n",
            "Iteration:  93% 336/361 [05:57<00:26,  1.05s/it]\u001b[A\n",
            "Iteration:  93% 337/361 [05:58<00:25,  1.04s/it]\u001b[A\n",
            "Iteration:  94% 338/361 [05:59<00:23,  1.04s/it]\u001b[A\n",
            "Iteration:  94% 339/361 [06:00<00:22,  1.04s/it]\u001b[A\n",
            "Iteration:  94% 340/361 [06:01<00:21,  1.04s/it]\u001b[A\n",
            "Iteration:  94% 341/361 [06:02<00:20,  1.04s/it]\u001b[A\n",
            "Iteration:  95% 342/361 [06:03<00:19,  1.04s/it]\u001b[A\n",
            "Iteration:  95% 343/361 [06:04<00:18,  1.04s/it]\u001b[A\n",
            "Iteration:  95% 344/361 [06:05<00:17,  1.04s/it]\u001b[A\n",
            "Iteration:  96% 345/361 [06:06<00:16,  1.04s/it]\u001b[A\n",
            "Iteration:  96% 346/361 [06:07<00:15,  1.04s/it]\u001b[A\n",
            "Iteration:  96% 347/361 [06:08<00:14,  1.04s/it]\u001b[A\n",
            "Iteration:  96% 348/361 [06:09<00:13,  1.04s/it]\u001b[A\n",
            "Iteration:  97% 349/361 [06:10<00:12,  1.04s/it]\u001b[A\n",
            "Iteration:  97% 350/361 [06:11<00:11,  1.04s/it]\u001b[A\n",
            "Iteration:  97% 351/361 [06:12<00:10,  1.04s/it]\u001b[A\n",
            "Iteration:  98% 352/361 [06:13<00:09,  1.04s/it]\u001b[A\n",
            "Iteration:  98% 353/361 [06:14<00:08,  1.04s/it]\u001b[A\n",
            "Iteration:  98% 354/361 [06:15<00:07,  1.05s/it]\u001b[A\n",
            "Iteration:  98% 355/361 [06:16<00:06,  1.04s/it]\u001b[A\n",
            "Iteration:  99% 356/361 [06:18<00:05,  1.05s/it]\u001b[A\n",
            "Iteration:  99% 357/361 [06:19<00:04,  1.05s/it]\u001b[A\n",
            "Iteration:  99% 358/361 [06:20<00:03,  1.05s/it]\u001b[A\n",
            "Iteration:  99% 359/361 [06:21<00:02,  1.05s/it]\u001b[A\n",
            "Iteration: 100% 360/361 [06:22<00:01,  1.05s/it]\u001b[A\n",
            "Iteration: 100% 361/361 [06:23<00:00,  1.06s/it]\n",
            "Epoch: 100% 2/2 [12:18<00:00, 369.23s/it]\n",
            "05/14/2021 09:59:56 - INFO - __main__ -    global_step = 722, average loss = 2.580458791962621\n",
            "05/14/2021 09:59:56 - INFO - __main__ -   Saving model checkpoint to models/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1bEetZPjP_q7",
        "outputId": "72249695-6008-4a98-b125-86d516d76027"
      },
      "source": [
        "!python ru-gpts/generate_transformers.py \\\n",
        "    --model_type=gpt2 \\\n",
        "    --model_name_or_path=models/ \\\n",
        "    --k=10 \\\n",
        "    --p=0.98 \\\n",
        "    --length=100 \\\n",
        "    --repetition_penalty=3"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-05-07 09:54:52.706225: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
            "05/07/2021 09:55:00 - INFO - __main__ -   Namespace(device=device(type='cuda'), k=10, length=100, model_name_or_path='models/essays', model_type='gpt2', n_gpu=1, no_cuda=False, num_return_sequences=1, p=0.98, padding_text='', prompt='', repetition_penalty=3.0, seed=42, stop_token='</s>', temperature=1.0, xlm_language='')\n",
            "Context >>> православные храмы станут\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "ruGPT:\n",
            "православные храмы станут музеями\n",
            "Context >>> В России\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "ruGPT:\n",
            "В России за год выявили более 500 новых случаев COVID-19\n",
            "Context >>> Москва\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "ruGPT:\n",
            "Москва\n",
            "Context >>> Песков объявил\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "ruGPT:\n",
            "Песков объявил о задержании двух предполагаемых участников беспорядков в Москве\n",
            "Context >>> Путин высказал\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "ruGPT:\n",
            "Путин высказал сожаление, что не может найти работу после того как уволился министр финансов России\n",
            "Context >>> Песков озабочен вопросами\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "ruGPT:\n",
            "Песков озабочен вопросами о состоянии здоровья россиян\n",
            "Context >>> В России открыли первый в мире\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "ruGPT:\n",
            "В России открыли первый в мире город со стеклянным полом\n",
            "Context >>> Петров и Боширов\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "ruGPT:\n",
            "Петров и Боширов потребовали от правительства отменить штрафы за отсутствие вакцины Спутник V\n",
            "Context >>> В Чехии создадут\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "ruGPT:\n",
            "В Чехии создадут памятник Гитлеру\n",
            "Context >>> В госдуме заявили об отсутствии\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "ruGPT:\n",
            "В госдуме заявили об отсутствии каких-то новых законов, которые бы обязали чиновников платить за коммунальные услуги\n",
            "Context >>> Патриарх Кирилл опроверг слухи\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "ruGPT:\n",
            "Патриарх Кирилл опроверг слухи о планах Путина посетить Россию\n",
            "Context >>> Путин потребовал от \n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "ruGPT:\n",
            "Путин потребовал от  Навального и других оппозиционеров прекратить акцию 31 января\n",
            "Context >>> Кремль заявил, что готов\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "ruGPT:\n",
            "Кремль заявил, что готов к отмене антироссийских санкций. Но потом отказался из-за критики в адрес Москвы и Китая\n",
            "Context >>> В РПЦ отметили, что\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "ruGPT:\n",
            "В РПЦ отметили, что после смерти отца в 1996 году она была закрыта из-за нехватки мест\n",
            "Context >>> Саратовский бизнесмен\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "ruGPT:\n",
            "Саратовский бизнесмен купил дом на Рублево-Успенском шоссе для своего сына. Это первая подобная сделка за два года\n",
            "Context >>> В США переименовали улицу в честь\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "ruGPT:\n",
            "В США переименовали улицу в честь Джорджа Флойда\n",
            "Context >>> Джордж Флойд станет\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "ruGPT:\n",
            "Джордж Флойд станет продюсером нового альбома Black Star. Теперь он будет работать на продюсера группы Pink Floyd\n",
            "Context >>> Дональд Трамп уйдет с поста\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "ruGPT:\n",
            "Дональд Трамп уйдет с поста президента США\n",
            "Context >>> Новый президент США\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "ruGPT:\n",
            "Новый президент США Дональд Трамп стал первым президентом Америки, кто поддержал идею легализации однополых союзов в Европе. В стране ввели режим чрезвычайной ситуации\n",
            "Context >>> В Роскосмосе создали\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "ruGPT:\n",
            "В Роскосмосе создали ракету, которая может летать в космос\n",
            "Context >>> Европейский союз легализировал\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "ruGPT:\n",
            "Европейский союз легализировал однополые союзы. Это очень хорошо, но не совсем правильно\n",
            "Context >>> В Амстердаме хотят\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "ruGPT:\n",
            "В Амстердаме хотят построить новый небоскреб в Москве\n",
            "Context >>> В Китае создали первый в мире\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "ruGPT:\n",
            "В Китае создали первый в мире автомобиль. Это машина с двойным управлением, которая может ехать без рук\n",
            "Context >>> В Китае запретили\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "ruGPT:\n",
            "В Китае запретили использование алкоголя в медицинских целях\n",
            "Context >>> В России запретили\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "ruGPT:\n",
            "В России запретили продажу вакцины против COVID-19\n",
            "Context >>> Россияне стали\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "ruGPT:\n",
            "Россияне стали больше ходить в магазин за покупками\n",
            "Context >>> В России ужесточили\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "ruGPT:\n",
            "В России ужесточили правила самоизоляции\n",
            "Context >>> Навальный прокомментировал\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "ruGPT:\n",
            "Навальный прокомментировал смерть своего друга\n",
            "Context >>> Песков о Навальном: \n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "ruGPT:\n",
            "Песков о Навальном:  в России за год выявлено больше 500 новых случаев коронавируса\n",
            "Context >>> Пациент берлинской клиники\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "ruGPT:\n",
            "Пациент берлинской клиники умер от коронавируса. Он заразился через открытый доступ в клинике, которая находится по адресу: Москва ул., дзержинского 9а\n",
            "Context >>> Traceback (most recent call last):\n",
            "  File \"ru-gpts/generate_transformers.py\", line 268, in <module>\n",
            "    main()\n",
            "  File \"ru-gpts/generate_transformers.py\", line 213, in main\n",
            "    prompt_text = args.prompt if args.prompt else input(\"Context >>> \")\n",
            "KeyboardInterrupt\n",
            "^C\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pdx7QCvGT2SP",
        "outputId": "83b67080-8d18-443c-d5db-633c11b00b4c"
      },
      "source": [
        "!python ru-gpts/generate_transformers.py \\\n",
        "    --model_type=gpt2 \\\n",
        "    --model_name_or_path=models/ \\\n",
        "    --k=10 \\\n",
        "    --p=0.98 \\\n",
        "    --length=100 \\\n",
        "    --repetition_penalty=3"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-05-07 10:11:32.442401: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
            "05/07/2021 10:11:41 - INFO - __main__ -   Namespace(device=device(type='cuda'), k=10, length=100, model_name_or_path='models/essays', model_type='gpt2', n_gpu=1, no_cuda=False, num_return_sequences=1, p=0.98, padding_text='', prompt='', repetition_penalty=3.0, seed=42, stop_token='</s>', temperature=1.0, xlm_language='')\n",
            "Context >>> В России признали инагентом\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "ruGPT:\n",
            "В России признали инагентом вируса коронавируса\n",
            "Context >>> В США установили\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "ruGPT:\n",
            "В США установили рекорд по смертности от коронавируса\n",
            "Context >>> Россия закрывает\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "ruGPT:\n",
            "Россия закрывает границы с Польшей, Литвой и Белоруссией\n",
            "Context >>> Лукашенко опроверг слухи\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "ruGPT:\n",
            "Лукашенко опроверг слухи о возможном присоединении Крыма к России\n",
            "Context >>> Российские дипломаты объявили\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "ruGPT:\n",
            "Российские дипломаты объявили о задержании двух сотрудников Росприроднадзора за участие в несогласованном митинге\n",
            "Context >>> Роскомнадзор заблокировал\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "ruGPT:\n",
            "Роскомнадзор заблокировал сайт, который предлагал клиентам хранить данные клиентов. Но там их просто не оказалось\n",
            "Context >>> Пентагон: \n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "ruGPT:\n",
            "Пентагон:  в центре Москвы произошел пожар\n",
            "Context >>> В России построят храм в честь\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "ruGPT:\n",
            "В России построят храм в честь пророка Илии\n",
            "Context >>> В России построят храм\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "ruGPT:\n",
            "В России построят храм в честь Святого Николая Чудотворца. На строительство уйдет более 10 лет\n",
            "Context >>> Новый храм будет\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "ruGPT:\n",
            "Новый храм будет закрыт\n",
            "Context >>> Навальный вернулся\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "ruGPT:\n",
            "Навальный вернулся на Украину. Его нашли в Москве после обыска\n",
            "Context >>> В центре Москвы\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "ruGPT:\n",
            "В центре Москвы задержаны еще пять человек\n",
            "Context >>> На митинге\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "ruGPT:\n",
            "На митинге в Петербурге задержаны более 100 человек\n",
            "Context >>> Милонов зявил о\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "ruGPT:\n",
            "Милонов зявил о намерении провести в России референдум\n",
            "Context >>> Путин о коронавирусе: \n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "ruGPT:\n",
            "Путин о коронавирусе:  Это очень опасно\n",
            "Context >>> Печенеги\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "ruGPT:\n",
            "Печенеги не стали признавать Крым частью России. Вот почему это происходит\n",
            "Context >>> Печенеги и половцы\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "ruGPT:\n",
            "Печенеги и половцы из Сибири, погибшие во время эпидемии ЧС\n",
            "Context >>> Роскомос создаст\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "ruGPT:\n",
            "Роскомос создаст свой банк\n",
            "Context >>> Сбербанк поменял\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "ruGPT:\n",
            "Сбербанк поменял логотип и эмблему на латиницу\n",
            "Context >>> Билл Гейтс выпустил\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "ruGPT:\n",
            "Билл Гейтс выпустил сборник своих песен\n",
            "Context >>> Американская суперзвезда\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "ruGPT:\n",
            "Американская суперзвезда: на ней нашли следы наркотиков\n",
            "Context >>> лол\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "ruGPT:\n",
            "лолия, которая была главной целью протестов против повышения пенсионного возраста. Она не принесла никаких результатов после того случая\n",
            "Context >>> Сталин\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "ruGPT:\n",
            "Сталин:  я хотел бы, чтобы вы были у меня в гостях. А что вам там делать\n",
            "Context >>> Российские дипломат\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "ruGPT:\n",
            "Российские дипломат  об отношениях США и России на фоне отравления Скрипалей\n",
            "Context >>> МКС планируют\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "ruGPT:\n",
            "МКС планируют построить в Подмосковье новый завод по производству бифидобактерий\n",
            "Context >>> в Подмосковье\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "ruGPT:\n",
            "в Подмосковье, по которому не ездят в автомобиле с детьми\n",
            "Context >>> Рамзан Кадыров потребовал\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "ruGPT:\n",
            "Рамзан Кадыров потребовал от России прекратить преследование чеченского блогера\n",
            "Context >>> Traceback (most recent call last):\n",
            "  File \"ru-gpts/generate_transformers.py\", line 268, in <module>\n",
            "    main()\n",
            "  File \"ru-gpts/generate_transformers.py\", line 213, in main\n",
            "    prompt_text = args.prompt if args.prompt else input(\"Context >>> \")\n",
            "KeyboardInterrupt\n",
            "^C\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A9pwvYG2dBna",
        "outputId": "962431de-347f-4774-ed95-25999c765b3e"
      },
      "source": [
        "!python ru-gpts/generate_transformers.py \\\n",
        "    --model_type=gpt2 \\\n",
        "    --model_name_or_path=models/ \\\n",
        "    --k=10 \\\n",
        "    --p=0.98 \\\n",
        "    --length=100 \\\n",
        "    --repetition_penalty=3"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-05-13 06:40:03.375403: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
            "05/13/2021 06:40:12 - INFO - __main__ -   Namespace(device=device(type='cuda'), k=10, length=100, model_name_or_path='models/', model_type='gpt2', n_gpu=1, no_cuda=False, num_return_sequences=1, p=0.98, padding_text='', prompt='', repetition_penalty=3.0, seed=42, stop_token='</s>', temperature=1.0, xlm_language='')\n",
            "Context >>> Путин поручил\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "ruGPT:\n",
            "Путин поручил проверить соблюдение требований закона о тишине в российских школах\n",
            "Context >>> Меркель сообщила\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "ruGPT:\n",
            "Меркель сообщила о гибели в ДТП двух десятков россиян\n",
            "Context >>> Traceback (most recent call last):\n",
            "  File \"ru-gpts/generate_transformers.py\", line 268, in <module>\n",
            "    main()\n",
            "  File \"ru-gpts/generate_transformers.py\", line 213, in main\n",
            "    prompt_text = args.prompt if args.prompt else input(\"Context >>> \")\n",
            "KeyboardInterrupt\n",
            "^C\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g2Ny-0o_aqJ8"
      },
      "source": [
        "!mv models /gdrive/MyDrive/neurama/models"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mD9mOfE0Xn5y"
      },
      "source": [
        "# Production"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G2fihWWobGO2",
        "outputId": "2b56580f-2063-41a5-f86c-e49fe4327752"
      },
      "source": [
        "!pip install python-telegram-bot --upgrade"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting python-telegram-bot\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e4/44/1726f407387a7332a08b4e95211380b3bda185cedbe73d1058010136e695/python_telegram_bot-13.5-py3-none-any.whl (455kB)\n",
            "\u001b[K     |████████████████████████████████| 460kB 7.8MB/s \n",
            "\u001b[?25hCollecting APScheduler==3.6.3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f3/34/9ef20ed473c4fd2c3df54ef77a27ae3fc7500b16b192add4720cab8b2c09/APScheduler-3.6.3-py2.py3-none-any.whl (58kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 8.9MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: pytz>=2018.6 in /usr/local/lib/python3.7/dist-packages (from python-telegram-bot) (2018.9)\n",
            "Requirement already satisfied, skipping upgrade: certifi in /usr/local/lib/python3.7/dist-packages (from python-telegram-bot) (2020.12.5)\n",
            "Requirement already satisfied, skipping upgrade: tornado>=5.1 in /usr/local/lib/python3.7/dist-packages (from python-telegram-bot) (5.1.1)\n",
            "Requirement already satisfied, skipping upgrade: setuptools>=0.7 in /usr/local/lib/python3.7/dist-packages (from APScheduler==3.6.3->python-telegram-bot) (56.1.0)\n",
            "Requirement already satisfied, skipping upgrade: six>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from APScheduler==3.6.3->python-telegram-bot) (1.15.0)\n",
            "Requirement already satisfied, skipping upgrade: tzlocal>=1.2 in /usr/local/lib/python3.7/dist-packages (from APScheduler==3.6.3->python-telegram-bot) (1.5.1)\n",
            "Installing collected packages: APScheduler, python-telegram-bot\n",
            "Successfully installed APScheduler-3.6.3 python-telegram-bot-13.5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SKzbt8AUbGs1"
      },
      "source": [
        "import logging\n",
        "\n",
        "from telegram import Update, ForceReply\n",
        "from telegram.ext import Updater, CommandHandler, MessageHandler, Filters, CallbackContext\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
        "\n",
        "from transformers import AutoTokenizer, AutoModelWithLMHead\n",
        "\n",
        "# Enable logging\n",
        "logging.basicConfig(\n",
        "    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s', level=logging.INFO\n",
        ")\n",
        "\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "class Bot:\n",
        "    def __init__(self, model_path):\n",
        "        self.model_path = model_path\n",
        "        self.tokenizer = GPT2Tokenizer.from_pretrained(self.model_path)\n",
        "        self.model = GPT2LMHeadModel.from_pretrained(self.model_path)\n",
        "\n",
        "        # self.tokenizer = AutoTokenizer.from_pretrained(\"sberbank-ai/rugpt3small_based_on_gpt2\")\n",
        "        # self.model = AutoModelWithLMHead.from_pretrained(\"sberbank-ai/rugpt3small_based_on_gpt2\")\n",
        "        self.model.cuda()\n",
        "\n",
        "        self.updater = Updater(token='')\n",
        "        self.dispatcher = self.updater.dispatcher\n",
        "\n",
        "    def bot_response(self, input):\n",
        "        from random import choice\n",
        "        input = self.tokenizer.encode(input, return_tensors=\"pt\")\n",
        "\n",
        "        max_leng = choice([50, 100, 130, 150])\n",
        "        top_p = choice([0.9, 0.92, 0.95, 0.98])\n",
        "        out = self.model.generate(input.cuda(), max_length=max_leng, repetition_penalty=3.0, do_sample=True, top_k=15, top_p=top_p, temperature=2.0)\n",
        "        out = self.tokenizer.decode(out[0])\n",
        "        return out[:out.find('</s>')]\n",
        "\n",
        "    def textMessage(self, update: Update, _: CallbackContext):\n",
        "        message = update.message.text\n",
        "        response = self.bot_response(message)\n",
        "        update.message.reply_text(response)\n",
        "\n",
        "    def startCommand(self, update: Update, _: CallbackContext) -> None:\n",
        "        user = update.effective_user\n",
        "        update.message.reply_markdown_v2(\n",
        "            fr'Hi {user.mention_markdown_v2()}\\!',\n",
        "            reply_markup=ForceReply(selective=True),\n",
        "        )\n",
        "\n",
        "    def start(self):\n",
        "        self.dispatcher.add_handler(CommandHandler('start', self.startCommand))\n",
        "        self.dispatcher.add_handler(MessageHandler(Filters.text & ~Filters.command, self.textMessage))\n",
        "        self.updater.start_polling()\n",
        "        self.updater.idle()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lpK67frmclmE"
      },
      "source": [
        "bot = Bot('/gdrive/MyDrive/neurama/models')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HQr6VSSygbw8"
      },
      "source": [
        "# Default"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 107
        },
        "id": "edQ4X7j0WKdJ",
        "outputId": "df24c166-509d-45aa-9284-53c8cde7965c"
      },
      "source": [
        "bot.bot_response('Путин заявил о')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Путин заявил о том, что его компания не будет участвовать в торгах с «Росатомом»\\nhttps://ria.ru/politics20181203/. По мнению Путина это приведет к ухудшению ситуации на Украине и потере контрольного пакета акций холдинга \"Росэнергоатом\", пишет ТАСС со ссылкой источник агентства.\"Если вы считаете Россию участником переговоров или тендера - пожалуйста\" [из Кремля], то я вас очень прошу быть бдительным: мы будем смотреть все ваши предложения! Это же очевидно... В таком случае ничего хорошего для компании (как ее учредителя) нет...\" //источник http//kprf-irina'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 107
        },
        "id": "bDBel_weWPKc",
        "outputId": "0cc952cd-8834-4b38-aed3-38c189bd6ce4"
      },
      "source": [
        "bot.bot_response('В центре Москвы')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'В центре Москвы.  Это самый красивый храм во всей Москве! \\n\\n Выезд в Москву: от МКАД (5 км) - до Тимирязевского проспекта или около \"Борисовой Якитории\". 15 минут по Дмитровскому направлению, далее пешком 10-15 метров на запад к станции метро Спортивная улица... и еще через 20 километров выходите под Рязанским шоссе.... после чего переходим Калужское поле с левой стороны дороги..... дальше налево!!! :) Припарковав авто возле дома 1 можно сразу попасть ко дворнику чтобы забрать мусор))) На территории парковка тоже платная для жителей всех районов района!!!! ;) Ну а потом выезжаем уже домой – все чисто.. )) А теперь мы пойдем осматривать новый дом со смотрово'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "id": "bTULAFd8WTd-",
        "outputId": "43991f23-a0a0-4c03-c191-241ae5d4ce57"
      },
      "source": [
        "bot.bot_response('Илон Маск')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Илон Маск и его сын-близнец\\nЛена Шелестова.  \\\\tСлучайно ли они с Ионой встречались, если предположить? Как оказалось - да! Но кто тогда был на их свадьбе в Москв'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IHhRhQ_te7lK"
      },
      "source": [
        "# Fine-tuned"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "id": "eofcv9ahWq4z",
        "outputId": "9bfd0da4-a195-437f-b28d-0b3547408679"
      },
      "source": [
        "bot.bot_response('Путин заявил о')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Путин заявил о планах продать часть земли в Китае'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "id": "y5sWjhn1e_S4",
        "outputId": "82e8e826-6602-45b5-a671-b6d09a835eef"
      },
      "source": [
        "bot.bot_response('В центре Москвы')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'В центре Москвы задержано более тысячи человек. Ранее на их задержания вышли представители СК, УВД столицы  и ГИБДД города Махачкалы.'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "id": "8Iaewa_tfBQ3",
        "outputId": "0421808c-af21-4c82-9544-376f70b4eccf"
      },
      "source": [
        "bot.bot_response('Илон Маск')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Илон Маск объявил об уходе с поста главы Роскосмоса'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JDu0FzuyWXVd"
      },
      "source": [
        "# New Section"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UoPsi2vweoUN",
        "outputId": "bd950719-da2c-47ef-c681-71b06ea35602"
      },
      "source": [
        "bot.start()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-05-14 10:58:21,541 - apscheduler.scheduler - INFO - Scheduler started\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ],
          "name": "stderr"
        }
      ]
    }
  ]
}